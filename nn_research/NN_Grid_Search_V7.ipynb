{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0SGfc28-E2x",
        "outputId": "96dd0166-dd63-451d-8435-3bacce11b633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.24.0-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (23.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=08144bf40e3147b745a601009efb72dc8eb2981fb1fae9a1d2415e03f13b73f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, typeguard, smmap, setproctitle, sentry-sdk, docker-pycreds, tensorflow_addons, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.24.0 setproctitle-1.3.2 smmap-5.0.0 tensorflow_addons-0.20.0 typeguard-2.13.3 wandb-0.15.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUwPNVZL-GJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "34802b1a-dd3a-4006-c94d-07470091f3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as ks\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, mean_poisson_deviance, \n",
        "    brier_score_loss, roc_auc_score, roc_curve, RocCurveDisplay\n",
        ")\n",
        "\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import wandb\n",
        "wandb.login(relogin = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SocNtEhZEDMG"
      },
      "source": [
        "# Prep Data Once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48p8QEt7ECUP"
      },
      "outputs": [],
      "source": [
        "def filter_nested_array(x, keep):\n",
        "  result = [[y[key] for key in keep] for y in x]\n",
        "\n",
        "  return np.array(result, dtype = 'object')\n",
        "\n",
        "def prepare_row(row):\n",
        "  # Figure out Claims\n",
        "  claims_keep_key = ['bi_ind', 'coll_ind', 'comp_ind', 'ers_ind', 'mpc_ind', 'pd_ind', 'ubi_ind',\n",
        "                      'veh_had_bi_cov_ind', 'veh_had_coll_cov_ind', 'veh_had_comp_cov_ind', 'veh_had_ers_cov_ind', \n",
        "                     'veh_had_mpc_cov_ind', 'veh_had_pd_cov_ind', 'veh_had_ubi_cov_ind']\n",
        "                      \n",
        "  other_claims = filter_nested_array(row['other_claims'], claims_keep_key)\n",
        "  other_claim_cnt = len(other_claims)\n",
        "  if other_claim_cnt > 0:\n",
        "    other_claims = np.append(other_claims, np.zeros([len(other_claims),1]), 1)\n",
        "\n",
        "  veh_claims = filter_nested_array(row['vehicle_claims'], claims_keep_key)\n",
        "  claim_cnt = len(veh_claims)\n",
        "  if claim_cnt > 0:\n",
        "    veh_claims = np.append(veh_claims, np.ones([len(veh_claims),1]), 1)\n",
        "\n",
        "  if claim_cnt + other_claim_cnt == 0:\n",
        "      all_claims = np.array([[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
        "  elif claim_cnt == 0:\n",
        "    all_claims = other_claims\n",
        "  elif other_claim_cnt == 0:\n",
        "    all_claims = veh_claims\n",
        "  else:\n",
        "    all_claims = np.append(veh_claims, other_claims, axis = 0)\n",
        "\n",
        "  all_claims = tf.ragged.constant([all_claims.astype('float16')], ragged_rank = 1, inner_shape = (15,))\n",
        "\n",
        "  # Figure Out Drivers\n",
        "  drivers = filter_nested_array(row['driver_info'], ['driver_age', 'driver_gender', 'driver_tenure'])\n",
        "  drivers[:, 0] = (drivers[:, 0] - 50)/50\n",
        "  drivers[:, 1] = np.where(drivers[:, 1] == 'm', 1, 0)\n",
        "  drivers[:, 2] = (drivers[:, 2] - 10)/10\n",
        "  drivers = tf.ragged.constant([drivers.astype('float16')], ragged_rank = 1, inner_shape = (3,))\n",
        "\n",
        "  # Figure out Vehicles\n",
        "  vehicles = filter_nested_array(row['household_vehicles_info'], ['this_vehicle_ind', 'vehicle_age', 'vehicle_type', 'vehicle_years_owned'])\n",
        "  vehicles[:, 1] = (vehicles[:, 1] - 15)/15\n",
        "  vehicles[:, 3] = (vehicles[:, 3] - 15)/15\n",
        "\n",
        "  veh_type = vehicles[:, 2]\n",
        "  vehicles[:, 2] = np.where(veh_type == 'van', 1, 0) + np.where(veh_type == 'sedan', 2, 0) + np.where(veh_type == 'sports car', 3, 0) + np.where(veh_type == 'suv', 4, 0)\n",
        "  vehicles = tf.ragged.constant([vehicles.astype('float16')], ragged_rank = 1, inner_shape = (4,))\n",
        "\n",
        "  other = [(row['credit_score'] - 600)/500,\n",
        "           (row['garaging_location'] == 'country') * 1 + (row['garaging_location'] == 'downtown') * 2, \n",
        "           (row['household_tenure'] - 15)/10,\n",
        "           (row['multiline_houses']/2),\n",
        "           row['multiline_rental'],\n",
        "           row['multiline_personal_article_policy'],\n",
        "           row['multiline_personal_liability_umbrella'],\n",
        "           (row['vehicle_count']-3)/3,\n",
        "           (row['annual_mileage'] - 10000)/10000,\n",
        "           (row['vehicle_age'] - 15)/15,\n",
        "           np.where(row['vehicle_type'] == 'van', 1, 0) + np.where(row['vehicle_type'] == 'sedan', 2, 0) + np.where(row['vehicle_type'] == 'sports car', 3, 0) + np.where(row['vehicle_type'] == 'suv', 4, 0),\n",
        "           (row['vehicle_years_owned'] - 10)/15,\n",
        "           (row['max_driver_age'] - 45)/45,\n",
        "           (row['min_driver_age'] - 45)/45,\n",
        "           (row['mean_driver_age'] - 45)/45,\n",
        "           (row['min_driver_tenure'] - 30)/30,\n",
        "           (row['youthful_driver_count'])/4,\n",
        "           row['driver_count']/5,\n",
        "           row['coverage_bi'],\n",
        "           row['coverage_coll'],\n",
        "           row['coverage_comp'],\n",
        "           row['coverage_ers'],\n",
        "           row['coverage_mpc'],\n",
        "           row['coverage_pd'],\n",
        "           row['coverage_ubi']      \n",
        "           ]\n",
        "  other = tf.constant(value = np.array(other, dtype = 'float16'))\n",
        "\n",
        "  target = [\n",
        "      row['vehicle_claim_cnt_pd_0'],\n",
        "      row['vehicle_claim_cnt_coll_0'],\n",
        "      row['vehicle_claim_cnt_bi_0'],\n",
        "      row['vehicle_claim_cnt_mpc_0']\n",
        "  ]\n",
        "\n",
        "  target = tf.constant(value = np.array(target, dtype = 'float16'))\n",
        "\n",
        "  result = {\n",
        "      'driver_info': drivers,\n",
        "      'vehicle_info': vehicles,\n",
        "      'claims_info': all_claims,\n",
        "      'other_data': other,\n",
        "      'target': target\n",
        "  }\n",
        "\n",
        "  return result\n",
        "\n",
        "ragged = lambda y : tf.concat(y.to_list(), axis = 0)\n",
        "\n",
        "def prep_one_datas(features):\n",
        "\n",
        "  x = [\n",
        "      ragged(features['driver_info']), \n",
        "      ragged(features['vehicle_info']), \n",
        "      ragged(features['claims_info']), \n",
        "      tf.convert_to_tensor(features['other_data'].to_list())\n",
        "  ]\n",
        "\n",
        "  y = tf.convert_to_tensor(features['target'].to_list())\n",
        "\n",
        "  return x,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83AJkQAPEOHm",
        "outputId": "8e843080-5c22-4cdd-86a4-9dee1a0da889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtylerrosacker2022\u001b[0m (\u001b[33mmsds_498_claims_modeling\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_185146-1piphat8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/1piphat8' target=\"_blank\">Data Prep for NN - 2023-05-29-18-51-45</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/1piphat8' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/1piphat8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact sythetic_data:v5, 153.76MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:7.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Data Prep for NN - 2023-05-29-18-51-45</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/1piphat8' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/1piphat8</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_185146-1piphat8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "with wandb.init(\n",
        "      project=\"claims_modeling\",\n",
        "      group = 'Data Prep',\n",
        "      name = f'Data Prep for NN - {datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}',\n",
        "      notes=\"Prep for NN Training, No Model Build!\",\n",
        "      tags=[\"data\"]) as run:\n",
        "    datas = run.use_artifact('msds_498_claims_modeling/claims_modeling/sythetic_data:v5')\n",
        "    directory = datas.download(root = 'datasets')\n",
        "\n",
        "    train_features = pd.read_parquet('datasets/split=train') \\\n",
        "      .apply(prepare_row, axis = 1, result_type = 'expand')\n",
        "\n",
        "    test_features = pd.read_parquet('datasets/split=test')\\\n",
        "      .apply(prepare_row, axis = 1, result_type = 'expand')\n",
        "\n",
        "    val_features = pd.read_parquet('datasets/split=validation')\\\n",
        "      .apply(prepare_row, axis = 1, result_type = 'expand')\n",
        "\n",
        "    train_x, train_y = prep_one_datas(train_features)\n",
        "    test_x, test_y = prep_one_datas(test_features)\n",
        "    val_x, val_y = prep_one_datas(val_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsRQbF-rEINK"
      },
      "source": [
        "# Model Train Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0y3ubPr-kH2"
      },
      "outputs": [],
      "source": [
        "def define_loss(weights):\n",
        "  def weighted_loss(y_true, y_pred):\n",
        "    fun = tf.keras.losses.Poisson()\n",
        "    #fun = tf.keras.losses.MeanSquaredError()\n",
        "    loss = 0\n",
        "\n",
        "    loss += weights[0] * fun(y_true[:, 0], y_pred[:, 0])\n",
        "    loss += weights[1] * fun(y_true[:, 1], y_pred[:, 1])\n",
        "    loss += weights[2] * fun(y_true[:, 2], y_pred[:, 2])\n",
        "    loss += weights[3] * fun(y_true[:, 3], y_pred[:, 3])\n",
        "\n",
        "    return loss\n",
        "  \n",
        "  return weighted_loss\n",
        "\n",
        "def build_basic_ragged_layers(name, input_node, width, dropout, agged = True):\n",
        "  dense_1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(width, \n",
        "                                        name = f\"{name}_Info_Dense\",\n",
        "                                        activation = tfa.activations.mish,\n",
        "                                        kernel_initializer='lecun_normal'\n",
        "                                        ))(input_node)\n",
        "  normed = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(dense_1)  \n",
        "  drop = tf.keras.layers.TimeDistributed(tf.keras.layers.AlphaDropout(dropout))(normed)\n",
        "  \n",
        "  # dense_2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(width, \n",
        "  #                                       name = f\"{name}_Info_Dense_2\",\n",
        "  #                                       activation = tfa.activations.mish,\n",
        "  #                                       kernel_initializer='lecun_normal'\n",
        "  #                                       ))(drop)\n",
        "  # normed_2 = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(dense_2)\n",
        "  # drop_2 = tf.keras.layers.TimeDistributed(tf.keras.layers.AlphaDropout(dropout))(normed_2)\n",
        "\n",
        "  # combined = tf.keras.layers.Add()([drop, drop_2])\n",
        "\n",
        "  if agged:\n",
        "    agged_sum = tf.math.reduce_sum(drop, 1)\n",
        "    agged_max = tf.math.reduce_max(drop, 1)\n",
        "    return tf.keras.layers.Concatenate()([agged_sum, agged_max])\n",
        "  else:\n",
        "    return drop\n",
        "\n",
        "def build_basic_combined_layers(name, input_node, width, dropout):\n",
        "  dense = tf.keras.layers.Dense(width, \n",
        "                                  name = f\"Res_Layer_{name}\",\n",
        "                                  activation = tfa.activations.mish,\n",
        "                                  kernel_initializer='lecun_normal'\n",
        "                                  )(input_node)\n",
        "  #leaky =  tf.keras.layers.LeakyReLU(alpha=leakiness)(dense)\n",
        "  drop = tf.keras.layers.AlphaDropout(dropout)(dense)\n",
        "  norm = tf.keras.layers.BatchNormalization()(drop)\n",
        "\n",
        "  return norm\n",
        "\n",
        "\n",
        "def build_model(run):\n",
        "  # driver_info\n",
        "  driver_input = ks.Input(shape = (None, 3), name = 'driver_info')\n",
        "  driver_agged = build_basic_ragged_layers('driver', driver_input, \n",
        "                                           width = run.config['driver_dense'],\n",
        "                                           dropout = run.config['dropout'],\n",
        "                                           agged = False)\n",
        "\n",
        "  # vehicle_info\n",
        "  vehicle_input = ks.Input(shape = (None, 4), name = 'vehicle_info')\n",
        "  vehicle_agged = build_basic_ragged_layers('vehicle', vehicle_input, \n",
        "                                           width = run.config['veh_dense'],\n",
        "                                           dropout = run.config['dropout'],\n",
        "                                           agged = False)\n",
        "  \n",
        "  driver_vehicle_cross = tf.keras.layers.MultiHeadAttention(num_heads=run.config['attention_heads'], \n",
        "                                                            key_dim = run.config['attention_dims'], \n",
        "                                                            output_shape = run.config['attention_output_dims']\n",
        "                                                            )(vehicle_agged, driver_agged)\n",
        "  attent_normed = tf.keras.layers.TimeDistributed(tf.keras.layers.BatchNormalization())(driver_vehicle_cross)  \n",
        "  attent_drop = tf.keras.layers.TimeDistributed(tf.keras.layers.AlphaDropout(run.config['dropout']))(attent_normed)\n",
        "  agged_att_sum = tf.math.reduce_sum(attent_drop, 1)\n",
        "  agged_att_max = tf.math.reduce_max(attent_drop, 1)\n",
        "\n",
        "  # claims_info\n",
        "  claims_input = ks.Input(shape = (None, 15), name = 'claims_info')\n",
        "  claims_agged = build_basic_ragged_layers('claims', claims_input, \n",
        "                                           width = run.config['claim_dense'],\n",
        "                                        dropout = run.config['dropout'])\n",
        "\n",
        "  # other_data\n",
        "  other_input = ks.Input(shape = (25,), name = 'other_data')\n",
        "  dense_other = build_basic_combined_layers(name = 'other', \n",
        "                                        input_node = other_input,\n",
        "                                        width = run.config['dense_other_block_width'],\n",
        "                                        dropout = run.config['dropout']\n",
        "                                        )\n",
        "  target_other = tf.keras.layers.Dense(4, \n",
        "                                      bias_initializer = tf.keras.initializers.Constant(value=run.config['initial_bias']),\n",
        "                                      activation=tf.keras.activations.exponential, \n",
        "                                      name = 'target_other')(dense_other)\n",
        "\n",
        "  #driver_agged, vehicle_agged, \n",
        "\n",
        "  combined = tf.keras.layers.Concatenate()([claims_agged, agged_att_sum, agged_att_max])\n",
        "  combined_norm = tf.keras.layers.BatchNormalization()(combined)\n",
        "\n",
        "\n",
        "  dense_1 = build_basic_combined_layers(name = '1', \n",
        "                                        input_node = combined_norm,\n",
        "                                        width = run.config['dense_res_block_width'],\n",
        "                                        dropout = run.config['dropout']\n",
        "                                        )\n",
        "  \n",
        "  # dense_2 = build_basic_combined_layers(name = '2', \n",
        "  #                                       input_node = dense_1,\n",
        "  #                                       width = run.config['dense_res_block_width'],\n",
        "  #                                       dropout = run.config['dropout']\n",
        "  #                                       )\n",
        "\n",
        "  # res_layer = tf.keras.layers.Add(name = \"Combined_Res_Result\")([dense_1, dense_2])\n",
        "  final_features = tf.keras.layers.Concatenate()([dense_1, combined_norm])\n",
        "\n",
        "  target_ragged = tf.keras.layers.Dense(4, \n",
        "                                      bias_initializer = tf.keras.initializers.Constant(value=0),\n",
        "                                      activation=tf.keras.activations.exponential, \n",
        "                                      name = 'target')(final_features)\n",
        "\n",
        "  final_prediction = tf.keras.layers.Multiply(name = \"Final_Prediction\")([target_ragged, target_other])\n",
        "\n",
        "  model = ks.Model(inputs = [driver_input, vehicle_input, claims_input, other_input],\n",
        "                outputs = [final_prediction])\n",
        "\n",
        "  model.compile(\n",
        "                optimizer=tf.keras.optimizers.experimental.AdamW(\n",
        "                    learning_rate = run.config['learning_rate'],\n",
        "                    weight_decay = run.config['weight_decay'], \n",
        "                    global_clipnorm=5.0,\n",
        "                    clipvalue=1,\n",
        "                    amsgrad=True\n",
        "                ), \n",
        "                loss = define_loss(run.config['loss_weight']))\n",
        "  \n",
        "  simple_model = ks.Model(inputs = [other_input],\n",
        "                outputs = [target_other])\n",
        "\n",
        "  simple_model.compile(\n",
        "                optimizer=tf.keras.optimizers.experimental.AdamW(\n",
        "                    learning_rate = run.config['learning_rate'],\n",
        "                    weight_decay = run.config['weight_decay'], \n",
        "                    global_clipnorm=5.0,\n",
        "                    clipvalue=1,\n",
        "                    amsgrad=True\n",
        "                ), \n",
        "                loss = define_loss(run.config['loss_weight']))\n",
        "  \n",
        "  return model, simple_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3-Elkaq-74l"
      },
      "outputs": [],
      "source": [
        "def log_stats(dataset_name, prediction, truth):\n",
        "  prediction = prediction[:, 0]\n",
        "  truth = truth[:, 0]\n",
        "  \n",
        "  prediction = np.clip(prediction, a_min = 0.001, a_max = np.inf)  \n",
        "  predicted_p_gt_0 = np.clip(1 - np.exp(-prediction), a_min = 0, a_max = 1)  \n",
        "  truth_capped = np.clip(truth, a_min = 0, a_max = 1)\n",
        "  truth_capped = np.clip(truth, a_min = 0, a_max = 1)\n",
        "\n",
        "  fpr, tpr, _ = roc_curve(truth_capped, predicted_p_gt_0)\n",
        "  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "  \n",
        "  metrics = {\n",
        "      f\"{dataset_name}_prediction_dist\": wandb.Histogram(prediction),\n",
        "      f\"{dataset_name}_mse\": mean_squared_error(truth, prediction), \n",
        "      f\"{dataset_name}_mae\": mean_absolute_error(truth, prediction),\n",
        "      f\"{dataset_name}_mean_poisson_deviance\": mean_poisson_deviance(truth, prediction),\n",
        "      f\"{dataset_name}_brier_loss\": brier_score_loss(truth_capped, predicted_p_gt_0),\n",
        "      f\"{dataset_name}_auc_score\": roc_auc_score(truth_capped, predicted_p_gt_0),\n",
        "      f\"{dataset_name}_roc\": roc_display.figure_\n",
        "    }\n",
        "  wandb.log(metrics)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbcAZUAO-GO2"
      },
      "outputs": [],
      "source": [
        "def main(config = None):\n",
        "  with wandb.init(\n",
        "      project=\"claims_modeling\",\n",
        "      group = 'NN Template V7 - Pretrained Simple',\n",
        "      name = f'NN Train - {datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}',\n",
        "      notes=\"Mutli-target Architecture NN\",\n",
        "      tags=[\"nn\"],\n",
        "      save_code = True,\n",
        "      sync_tensorboard=True,\n",
        "      config=config) as run:\n",
        "    datas = run.use_artifact('msds_498_claims_modeling/claims_modeling/sythetic_data:v5')\n",
        "    model, simple_model = build_model(run)\n",
        "\n",
        "    tf.keras.utils.plot_model(\n",
        "      model,\n",
        "      to_file='model.png',\n",
        "      show_shapes=True,\n",
        "      show_layer_names=True,\n",
        "      show_layer_activations=True,\n",
        "      show_trainable=True\n",
        "    )\n",
        "\n",
        "    artifact = wandb.Artifact(\n",
        "        name='model_arch_graph', \n",
        "        type='image'\n",
        "        )    \n",
        "\n",
        "    artifact.add_file(local_path='model.png')\n",
        "    run.log_artifact(artifact)\n",
        "\n",
        "    epochs = run.config['epochs'] // 4 + 1\n",
        "\n",
        "    simple_model.fit(train_x[3], \n",
        "              train_y, \n",
        "              epochs = epochs, \n",
        "              batch_size = run.config['batch_size'], \n",
        "              validation_data=(test_x[3], test_y))\n",
        "    \n",
        "    \n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(histogram_freq=1)\n",
        "\n",
        "    # Treat as transfer learning or nah\n",
        "    if run.config['keep_trainable'] == False:\n",
        "      simple_model.trainable = False\n",
        "      model.fit(train_x, \n",
        "                train_y, \n",
        "                epochs = 2 * epochs, \n",
        "                batch_size = run.config['batch_size'], \n",
        "                validation_data=(test_x, test_y),\n",
        "                callbacks=[tensorboard_callback])\n",
        "      \n",
        "      # Now really burn in!\n",
        "      simple_model.trainable = True\n",
        "      #K.set_value(model.optimizer.learning_rate, run.config['learning_rate'] * 0.1)\n",
        "      model.fit(train_x, \n",
        "                train_y, \n",
        "                epochs = epochs, \n",
        "                batch_size = run.config['batch_size'] * run.config['burnin_multiplier'], \n",
        "                validation_data=(test_x, test_y),\n",
        "                callbacks=[tensorboard_callback])\n",
        "      \n",
        "    else:\n",
        "      model.fit(train_x, \n",
        "                train_y, \n",
        "                epochs = 3 * epochs, \n",
        "                batch_size = run.config['batch_size'], \n",
        "                validation_data=(test_x, test_y),\n",
        "                callbacks=[tensorboard_callback])\n",
        "      \n",
        "    \n",
        "    train_pred = model.predict(train_x, batch_size = 1024)\n",
        "    test_pred = model.predict(test_x, batch_size = 1024)\n",
        "    val_pred = model.predict(val_x, batch_size = 1024)\n",
        "\n",
        "    log_stats('train', train_pred, train_y)\n",
        "    log_stats('test', test_pred, test_y)\n",
        "    log_stats('val', val_pred, val_y)\n",
        "\n",
        "    model.save('model')\n",
        "    wandb.save('model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTqtfKL3Jenz"
      },
      "source": [
        "# Grid Search!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1ot2J03-GRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9d77d93-ab56-4189-c4a5-bc1d28fff93b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j7t6n4pe with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_192024-j7t6n4pe</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j7t6n4pe' target=\"_blank\">NN Train - 2023-05-29-19-20-18</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j7t6n4pe' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j7t6n4pe</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 9s 7ms/step - loss: 0.2282 - val_loss: 0.2237\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2231 - val_loss: 0.2227\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2217 - val_loss: 0.2217\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2211 - val_loss: 0.2212\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2206 - val_loss: 0.2216\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2203 - val_loss: 0.2207\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2202 - val_loss: 0.2208\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2200 - val_loss: 0.2210\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2199 - val_loss: 0.2208\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2198 - val_loss: 0.2212\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2198 - val_loss: 0.2204\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2197 - val_loss: 0.2208\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2197 - val_loss: 0.2207\n",
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 38ms/step - loss: 0.2265 - val_loss: 0.2228\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2215 - val_loss: 0.2250\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2210 - val_loss: 0.2220\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2207 - val_loss: 0.2221\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2204 - val_loss: 0.2234\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2200 - val_loss: 0.2226\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2200 - val_loss: 0.2224\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2198 - val_loss: 0.2216\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2197 - val_loss: 0.2217\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 16s 33ms/step - loss: 0.2196 - val_loss: 0.2215\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2196 - val_loss: 0.2214\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2196 - val_loss: 0.2205\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2195 - val_loss: 0.2215\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 15s 34ms/step - loss: 0.2195 - val_loss: 0.2213\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2193 - val_loss: 0.2204\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2194 - val_loss: 0.2210\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2194 - val_loss: 0.2208\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2195 - val_loss: 0.2206\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2193 - val_loss: 0.2209\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2193 - val_loss: 0.2207\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2193 - val_loss: 0.2208\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2191 - val_loss: 0.2217\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2193 - val_loss: 0.2214\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2192 - val_loss: 0.2206\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2192 - val_loss: 0.2210\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2192 - val_loss: 0.2206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2189"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 7s 228ms/step - loss: 0.2189 - val_loss: 0.2206\n",
            "Epoch 2/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2187 - val_loss: 0.2206\n",
            "Epoch 3/13\n",
            "27/27 [==============================] - 7s 221ms/step - loss: 0.2187 - val_loss: 0.2206\n",
            "Epoch 4/13\n",
            "27/27 [==============================] - 7s 215ms/step - loss: 0.2187 - val_loss: 0.2205\n",
            "Epoch 5/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2187 - val_loss: 0.2205\n",
            "Epoch 6/13\n",
            "27/27 [==============================] - 7s 211ms/step - loss: 0.2186 - val_loss: 0.2206\n",
            "Epoch 7/13\n",
            "27/27 [==============================] - 7s 212ms/step - loss: 0.2186 - val_loss: 0.2205\n",
            "Epoch 8/13\n",
            "27/27 [==============================] - 7s 211ms/step - loss: 0.2185 - val_loss: 0.2207\n",
            "Epoch 9/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2186 - val_loss: 0.2204\n",
            "Epoch 10/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2186 - val_loss: 0.2205\n",
            "Epoch 11/13\n",
            "27/27 [==============================] - 7s 212ms/step - loss: 0.2185 - val_loss: 0.2206\n",
            "Epoch 12/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2186 - val_loss: 0.2205\n",
            "Epoch 13/13\n",
            "27/27 [==============================] - 7s 212ms/step - loss: 0.2186 - val_loss: 0.2205\n",
            "216/216 [==============================] - 5s 18ms/step\n",
            "63/63 [==============================] - 1s 17ms/step\n",
            "31/31 [==============================] - 1s 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▅█▃▄▆▄▄▃▃▃▂▁▃▂▁▂▂▁▂▁▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅█▃▄▆▄▄▃▃▃▂▁▃▂▁▂▂▁▂▁▂▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11557</td></tr><tr><td>test_auc_score</td><td>0.61425</td></tr><tr><td>test_brier_loss</td><td>0.07067</td></tr><tr><td>test_mae</td><td>0.14882</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4026</td></tr><tr><td>test_mse</td><td>0.0792</td></tr><tr><td>train/epoch_loss</td><td>0.21858</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62241</td></tr><tr><td>train_brier_loss</td><td>0.06981</td></tr><tr><td>train_mae</td><td>0.14808</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39894</td></tr><tr><td>train_mse</td><td>0.07918</td></tr><tr><td>val_auc_score</td><td>0.60778</td></tr><tr><td>val_brier_loss</td><td>0.06973</td></tr><tr><td>val_mae</td><td>0.14805</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40293</td></tr><tr><td>val_mse</td><td>0.07948</td></tr><tr><td>validation/epoch_loss</td><td>0.22052</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22052</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-20-18</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j7t6n4pe' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j7t6n4pe</a><br/>Synced 5 W&B file(s), 3 media file(s), 1 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_192024-j7t6n4pe/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hd8rre1q with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_193059-hd8rre1q</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hd8rre1q' target=\"_blank\">NN Train - 2023-05-29-19-30-53</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hd8rre1q' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hd8rre1q</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 4s 5ms/step - loss: 0.2752 - val_loss: 0.2709\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2707 - val_loss: 0.2945\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2714 - val_loss: 0.2719\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2712 - val_loss: 0.2722\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2706 - val_loss: 0.2746\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2705 - val_loss: 0.2700\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2707 - val_loss: 0.2695\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2705 - val_loss: 0.2703\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2702 - val_loss: 0.2699\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2701 - val_loss: 0.2715\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2701 - val_loss: 0.2757\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2701 - val_loss: 0.2707\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2697 - val_loss: 0.2748\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "429/431 [============================>.] - ETA: 0s - loss: 0.2828"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 26s 31ms/step - loss: 0.2829 - val_loss: 0.2746\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2714 - val_loss: 0.2695\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2714 - val_loss: 0.2710\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2717 - val_loss: 0.2774\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2714 - val_loss: 0.2736\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2713 - val_loss: 0.2694\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2708 - val_loss: 0.2709\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2717 - val_loss: 0.2769\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2713 - val_loss: 0.2703\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2708 - val_loss: 0.2702\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2707 - val_loss: 0.2698\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2707 - val_loss: 0.2728\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2705 - val_loss: 0.2751\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2708 - val_loss: 0.2702\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2707 - val_loss: 0.2717\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2702 - val_loss: 0.2698\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2705 - val_loss: 0.2737\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2705 - val_loss: 0.2732\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2696\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2698 - val_loss: 0.2716\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2740\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2706 - val_loss: 0.2729\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2701 - val_loss: 0.2696\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2703 - val_loss: 0.2713\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2757\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2700 - val_loss: 0.2699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 13s 27ms/step - loss: 0.2698 - val_loss: 0.2728\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2698 - val_loss: 0.2697\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2700 - val_loss: 0.2712\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2701 - val_loss: 0.2741\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2703 - val_loss: 0.2728\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2696 - val_loss: 0.2700\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2693 - val_loss: 0.2811\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2696 - val_loss: 0.2704\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2727\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2694 - val_loss: 0.2723\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2696 - val_loss: 0.2724\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2721\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 13s 27ms/step - loss: 0.2699 - val_loss: 0.2765\n",
            "216/216 [==============================] - 4s 12ms/step\n",
            "63/63 [==============================] - 1s 11ms/step\n",
            "31/31 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▂▁▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇███▁▁▂▂▂▃▃▃▃▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄▁▂▆▄▁▂▅▂▁▁▃▄▁▂▁▄▃▁▂▄▃▁▂▅▁▃▁▂▄▃▁█▂▃▃▃▃▅</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄▁▂▆▄▁▂▅▂▁▁▃▄▁▂▁▄▃▁▂▄▃▁▂▅▁▃▁▂▄▃▁█▂▃▃▃▃▅</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>16809</td></tr><tr><td>test_auc_score</td><td>0.60351</td></tr><tr><td>test_brier_loss</td><td>0.07211</td></tr><tr><td>test_mae</td><td>0.17984</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41824</td></tr><tr><td>test_mse</td><td>0.08106</td></tr><tr><td>train/epoch_loss</td><td>0.26989</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.60937</td></tr><tr><td>train_brier_loss</td><td>0.07134</td></tr><tr><td>train_mae</td><td>0.1792</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41609</td></tr><tr><td>train_mse</td><td>0.08115</td></tr><tr><td>val_auc_score</td><td>0.59882</td></tr><tr><td>val_brier_loss</td><td>0.07122</td></tr><tr><td>val_mae</td><td>0.17903</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41849</td></tr><tr><td>val_mse</td><td>0.08136</td></tr><tr><td>validation/epoch_loss</td><td>0.27648</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27648</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-30-53</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hd8rre1q' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hd8rre1q</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_193059-hd8rre1q/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fzie28zg with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4096\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_194116-fzie28zg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/fzie28zg' target=\"_blank\">NN Train - 2023-05-29-19-41-13</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/fzie28zg' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/fzie28zg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - 3s 10ms/step - loss: 0.2361 - val_loss: 0.2329\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2264 - val_loss: 0.2323\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2249 - val_loss: 0.2297\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2238 - val_loss: 0.2278\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2233 - val_loss: 0.2281\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2228 - val_loss: 0.2274\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2224 - val_loss: 0.2282\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2221 - val_loss: 0.2291\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2219 - val_loss: 0.2265\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2216 - val_loss: 0.2296\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2213 - val_loss: 0.2291\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2212 - val_loss: 0.2308\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2211 - val_loss: 0.2278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "54/54 [==============================] - ETA: 0s - loss: 34465.5117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 19s 106ms/step - loss: 34465.5117 - val_loss: 2596371712.0000\n",
            "Epoch 2/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2280 - val_loss: 2.3571\n",
            "Epoch 3/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2248 - val_loss: 0.2794\n",
            "Epoch 4/26\n",
            "54/54 [==============================] - 5s 74ms/step - loss: 0.2241 - val_loss: 0.2435\n",
            "Epoch 5/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2235 - val_loss: 0.2958\n",
            "Epoch 6/26\n",
            "54/54 [==============================] - 5s 72ms/step - loss: 0.2232 - val_loss: 0.2348\n",
            "Epoch 7/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2228 - val_loss: 0.2754\n",
            "Epoch 8/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2225 - val_loss: 0.2702\n",
            "Epoch 9/26\n",
            "54/54 [==============================] - 5s 75ms/step - loss: 0.2225 - val_loss: 0.2372\n",
            "Epoch 10/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2225 - val_loss: 0.2526\n",
            "Epoch 11/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2225 - val_loss: 0.2404\n",
            "Epoch 12/26\n",
            "54/54 [==============================] - 5s 74ms/step - loss: 0.2223 - val_loss: 0.2458\n",
            "Epoch 13/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2221 - val_loss: 0.2462\n",
            "Epoch 14/26\n",
            "54/54 [==============================] - 5s 72ms/step - loss: 0.2218 - val_loss: 0.2594\n",
            "Epoch 15/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2219 - val_loss: 0.2599\n",
            "Epoch 16/26\n",
            "54/54 [==============================] - 5s 68ms/step - loss: 0.2217 - val_loss: 0.2647\n",
            "Epoch 17/26\n",
            "54/54 [==============================] - 5s 76ms/step - loss: 0.2218 - val_loss: 0.2299\n",
            "Epoch 18/26\n",
            "54/54 [==============================] - 5s 68ms/step - loss: 0.2216 - val_loss: 0.2343\n",
            "Epoch 19/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2215 - val_loss: 0.2446\n",
            "Epoch 20/26\n",
            "54/54 [==============================] - 5s 70ms/step - loss: 0.2219 - val_loss: 0.2509\n",
            "Epoch 21/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2219 - val_loss: 0.2369\n",
            "Epoch 22/26\n",
            "54/54 [==============================] - 5s 74ms/step - loss: 0.2213 - val_loss: 0.2395\n",
            "Epoch 23/26\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2212 - val_loss: 0.2340\n",
            "Epoch 24/26\n",
            "54/54 [==============================] - 5s 75ms/step - loss: 0.2213 - val_loss: 0.2530\n",
            "Epoch 25/26\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2211 - val_loss: 0.2447\n",
            "Epoch 26/26\n",
            "54/54 [==============================] - 5s 72ms/step - loss: 0.2213 - val_loss: 0.2387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.2214"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 5s 773ms/step - loss: 0.2214 - val_loss: 0.2385\n",
            "Epoch 2/13\n",
            "4/4 [==============================] - 4s 757ms/step - loss: 0.2208 - val_loss: 0.2386\n",
            "Epoch 3/13\n",
            "4/4 [==============================] - 5s 780ms/step - loss: 0.2205 - val_loss: 0.2394\n",
            "Epoch 4/13\n",
            "4/4 [==============================] - 4s 778ms/step - loss: 0.2204 - val_loss: 0.2290\n",
            "Epoch 5/13\n",
            "4/4 [==============================] - 4s 761ms/step - loss: 0.2201 - val_loss: 0.2320\n",
            "Epoch 6/13\n",
            "4/4 [==============================] - 5s 760ms/step - loss: 0.2202 - val_loss: 0.2283\n",
            "Epoch 7/13\n",
            "4/4 [==============================] - 4s 736ms/step - loss: 0.2199 - val_loss: 0.2302\n",
            "Epoch 8/13\n",
            "4/4 [==============================] - 4s 781ms/step - loss: 0.2198 - val_loss: 0.2302\n",
            "Epoch 9/13\n",
            "4/4 [==============================] - 5s 781ms/step - loss: 0.2198 - val_loss: 0.2324\n",
            "Epoch 10/13\n",
            "4/4 [==============================] - 4s 738ms/step - loss: 0.2197 - val_loss: 0.2301\n",
            "Epoch 11/13\n",
            "4/4 [==============================] - 5s 808ms/step - loss: 0.2197 - val_loss: 0.2313\n",
            "Epoch 12/13\n",
            "4/4 [==============================] - 4s 750ms/step - loss: 0.2197 - val_loss: 0.2294\n",
            "Epoch 13/13\n",
            "4/4 [==============================] - 4s 762ms/step - loss: 0.2197 - val_loss: 0.2296\n",
            "216/216 [==============================] - 5s 14ms/step\n",
            "63/63 [==============================] - 1s 13ms/step\n",
            "31/31 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▂▃▃▃▄▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1456</td></tr><tr><td>test_auc_score</td><td>0.6113</td></tr><tr><td>test_brier_loss</td><td>0.07299</td></tr><tr><td>test_mae</td><td>0.15935</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.42189</td></tr><tr><td>test_mse</td><td>0.08409</td></tr><tr><td>train/epoch_loss</td><td>0.21966</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61613</td></tr><tr><td>train_brier_loss</td><td>0.07204</td></tr><tr><td>train_mae</td><td>0.15843</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41757</td></tr><tr><td>train_mse</td><td>0.08381</td></tr><tr><td>val_auc_score</td><td>0.60665</td></tr><tr><td>val_brier_loss</td><td>0.07198</td></tr><tr><td>val_mae</td><td>0.15849</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.42255</td></tr><tr><td>val_mse</td><td>0.08459</td></tr><tr><td>validation/epoch_loss</td><td>0.22964</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22964</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-41-13</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/fzie28zg' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/fzie28zg</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_194116-fzie28zg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 437ace50 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_194543-437ace50</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/437ace50' target=\"_blank\">NN Train - 2023-05-29-19-45-40</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/437ace50' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/437ace50</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 7ms/step - loss: 0.2769 - val_loss: 0.2734\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2716 - val_loss: 0.2719\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2701 - val_loss: 0.2739\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2693 - val_loss: 0.2752\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2692 - val_loss: 0.2742\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2689 - val_loss: 0.2737\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2687 - val_loss: 0.2729\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2685 - val_loss: 0.2724\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2685 - val_loss: 0.2740\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2684 - val_loss: 0.2748\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2683 - val_loss: 0.2730\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2682 - val_loss: 0.2734\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2682 - val_loss: 0.2762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "108/108 [==============================] - ETA: 0s - loss: 34.3148"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 19s 61ms/step - loss: 34.3148 - val_loss: 0.4137\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 6s 49ms/step - loss: 0.2717 - val_loss: 0.3056\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 6s 45ms/step - loss: 0.2710 - val_loss: 0.3113\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 6s 49ms/step - loss: 0.2706 - val_loss: 0.3173\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 6s 45ms/step - loss: 0.2707 - val_loss: 0.3096\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 6s 49ms/step - loss: 0.2696 - val_loss: 0.2866\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2701 - val_loss: 0.2884\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 6s 46ms/step - loss: 0.2700 - val_loss: 0.2803\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2699 - val_loss: 0.2772\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2693 - val_loss: 0.2807\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2694 - val_loss: 0.2754\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2688 - val_loss: 0.2746\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2689 - val_loss: 0.2749\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2688 - val_loss: 0.2749\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2686 - val_loss: 0.2831\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2687 - val_loss: 0.2744\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2683 - val_loss: 0.2773\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2686 - val_loss: 0.2735\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 6s 45ms/step - loss: 0.2684 - val_loss: 0.2744\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2684 - val_loss: 0.2750\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2683 - val_loss: 0.2747\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2681 - val_loss: 0.2733\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2682 - val_loss: 0.2784\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2680 - val_loss: 0.2765\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2680 - val_loss: 0.2714\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 6s 46ms/step - loss: 0.2680 - val_loss: 0.2740\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 5s 434ms/step - loss: 0.2677 - val_loss: 0.2742\n",
            "Epoch 2/13\n",
            "7/7 [==============================] - 4s 407ms/step - loss: 0.2675 - val_loss: 0.2728\n",
            "Epoch 3/13\n",
            "7/7 [==============================] - 4s 470ms/step - loss: 0.2673 - val_loss: 0.2730\n",
            "Epoch 4/13\n",
            "7/7 [==============================] - 4s 404ms/step - loss: 0.2672 - val_loss: 0.2736\n",
            "Epoch 5/13\n",
            "7/7 [==============================] - 4s 425ms/step - loss: 0.2672 - val_loss: 0.2729\n",
            "Epoch 6/13\n",
            "7/7 [==============================] - 4s 441ms/step - loss: 0.2672 - val_loss: 0.2729\n",
            "Epoch 7/13\n",
            "7/7 [==============================] - 4s 415ms/step - loss: 0.2671 - val_loss: 0.2731\n",
            "Epoch 8/13\n",
            "7/7 [==============================] - 4s 409ms/step - loss: 0.2671 - val_loss: 0.2729\n",
            "Epoch 9/13\n",
            "7/7 [==============================] - 4s 422ms/step - loss: 0.2670 - val_loss: 0.2734\n",
            "Epoch 10/13\n",
            "7/7 [==============================] - 4s 405ms/step - loss: 0.2669 - val_loss: 0.2731\n",
            "Epoch 11/13\n",
            "7/7 [==============================] - 4s 404ms/step - loss: 0.2670 - val_loss: 0.2733\n",
            "Epoch 12/13\n",
            "7/7 [==============================] - 4s 428ms/step - loss: 0.2671 - val_loss: 0.2726\n",
            "Epoch 13/13\n",
            "7/7 [==============================] - 4s 416ms/step - loss: 0.2669 - val_loss: 0.2728\n",
            "216/216 [==============================] - 4s 14ms/step\n",
            "63/63 [==============================] - 1s 17ms/step\n",
            "31/31 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██▁▁▁▂▂▂▂▃▃▃▃▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▃▃▃▃▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▃▃▃▃▂▂▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2899</td></tr><tr><td>test_auc_score</td><td>0.61373</td></tr><tr><td>test_brier_loss</td><td>0.07141</td></tr><tr><td>test_mae</td><td>0.15021</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41018</td></tr><tr><td>test_mse</td><td>0.08057</td></tr><tr><td>train/epoch_loss</td><td>0.26691</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61946</td></tr><tr><td>train_brier_loss</td><td>0.07053</td></tr><tr><td>train_mae</td><td>0.14944</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40613</td></tr><tr><td>train_mse</td><td>0.08044</td></tr><tr><td>val_auc_score</td><td>0.60889</td></tr><tr><td>val_brier_loss</td><td>0.07041</td></tr><tr><td>val_mae</td><td>0.14934</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41047</td></tr><tr><td>val_mse</td><td>0.08082</td></tr><tr><td>validation/epoch_loss</td><td>0.2728</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.2728</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-45-40</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/437ace50' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/437ace50</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_194543-437ace50/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w7ygz1ec with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4096\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_195047-w7ygz1ec</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/w7ygz1ec' target=\"_blank\">NN Train - 2023-05-29-19-50-44</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/w7ygz1ec' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/w7ygz1ec</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "54/54 [==============================] - 2s 10ms/step - loss: 0.2772 - val_loss: 0.3089\n",
            "Epoch 2/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2668 - val_loss: 0.3045\n",
            "Epoch 3/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2659 - val_loss: 0.2832\n",
            "Epoch 4/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2645 - val_loss: 0.2775\n",
            "Epoch 5/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.2786\n",
            "Epoch 6/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.2773\n",
            "Epoch 7/7\n",
            "54/54 [==============================] - 0s 6ms/step - loss: 0.2640 - val_loss: 0.2831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "53/54 [============================>.] - ETA: 0s - loss: 2.8988"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 18s 94ms/step - loss: 2.8628 - val_loss: 0.9713\n",
            "Epoch 2/14\n",
            "54/54 [==============================] - 4s 60ms/step - loss: 0.4420 - val_loss: 0.4742\n",
            "Epoch 3/14\n",
            "54/54 [==============================] - 4s 60ms/step - loss: 0.4321 - val_loss: 0.4435\n",
            "Epoch 4/14\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.4319 - val_loss: 0.4367\n",
            "Epoch 5/14\n",
            "54/54 [==============================] - 4s 59ms/step - loss: 0.4307 - val_loss: 0.4389\n",
            "Epoch 6/14\n",
            "54/54 [==============================] - 4s 58ms/step - loss: 0.4307 - val_loss: 0.4442\n",
            "Epoch 7/14\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.4296 - val_loss: 0.4493\n",
            "Epoch 8/14\n",
            "54/54 [==============================] - 4s 59ms/step - loss: 0.4303 - val_loss: 0.4426\n",
            "Epoch 9/14\n",
            "54/54 [==============================] - 4s 58ms/step - loss: 0.4315 - val_loss: 0.4373\n",
            "Epoch 10/14\n",
            "54/54 [==============================] - 5s 69ms/step - loss: 0.4298 - val_loss: 0.4481\n",
            "Epoch 11/14\n",
            "54/54 [==============================] - 4s 59ms/step - loss: 0.4295 - val_loss: 0.4531\n",
            "Epoch 12/14\n",
            "54/54 [==============================] - 4s 59ms/step - loss: 0.4303 - val_loss: 0.4546\n",
            "Epoch 13/14\n",
            "54/54 [==============================] - 5s 69ms/step - loss: 0.4300 - val_loss: 0.4490\n",
            "Epoch 14/14\n",
            "54/54 [==============================] - 4s 60ms/step - loss: 0.4299 - val_loss: 0.4498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "4/4 [==============================] - ETA: 0s - loss: 0.4284"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 4s 676ms/step - loss: 0.4284 - val_loss: 0.4509\n",
            "Epoch 2/7\n",
            "4/4 [==============================] - 4s 763ms/step - loss: 0.4285 - val_loss: 0.4525\n",
            "Epoch 3/7\n",
            "4/4 [==============================] - 4s 644ms/step - loss: 0.4284 - val_loss: 0.4554\n",
            "Epoch 4/7\n",
            "4/4 [==============================] - 4s 684ms/step - loss: 0.4284 - val_loss: 0.4549\n",
            "Epoch 5/7\n",
            "4/4 [==============================] - 4s 755ms/step - loss: 0.4282 - val_loss: 0.4476\n",
            "Epoch 6/7\n",
            "4/4 [==============================] - 4s 683ms/step - loss: 0.4282 - val_loss: 0.4488\n",
            "Epoch 7/7\n",
            "4/4 [==============================] - 4s 648ms/step - loss: 0.4281 - val_loss: 0.4478\n",
            "216/216 [==============================] - 5s 15ms/step\n",
            "63/63 [==============================] - 1s 12ms/step\n",
            "31/31 [==============================] - 0s 12ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▄▅▅▅▆▆▆▇▇█▁▁▂▂▃▃▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>784</td></tr><tr><td>test_auc_score</td><td>0.61072</td></tr><tr><td>test_brier_loss</td><td>0.07721</td></tr><tr><td>test_mae</td><td>0.18028</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4482</td></tr><tr><td>test_mse</td><td>0.09604</td></tr><tr><td>train/epoch_loss</td><td>0.42811</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61643</td></tr><tr><td>train_brier_loss</td><td>0.07618</td></tr><tr><td>train_mae</td><td>0.17934</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.44335</td></tr><tr><td>train_mse</td><td>0.0962</td></tr><tr><td>val_auc_score</td><td>0.60743</td></tr><tr><td>val_brier_loss</td><td>0.07615</td></tr><tr><td>val_mae</td><td>0.17945</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.44959</td></tr><tr><td>val_mse</td><td>0.09837</td></tr><tr><td>validation/epoch_loss</td><td>0.44784</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.44784</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-50-44</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/w7ygz1ec' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/w7ygz1ec</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_195047-w7ygz1ec/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zmwhp50a with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_195325-zmwhp50a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zmwhp50a' target=\"_blank\">NN Train - 2023-05-29-19-53-22</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zmwhp50a' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zmwhp50a</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 7ms/step - loss: 0.2740 - val_loss: 0.2690\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2658 - val_loss: 0.2663\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2644 - val_loss: 0.2649\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2638 - val_loss: 0.2662\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2633 - val_loss: 0.2658\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2628 - val_loss: 0.2669\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2627 - val_loss: 0.2645\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2625 - val_loss: 0.2642\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2623 - val_loss: 0.2638\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2623 - val_loss: 0.2644\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2620 - val_loss: 0.2652\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2622 - val_loss: 0.2650\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2620 - val_loss: 0.2635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "107/108 [============================>.] - ETA: 0s - loss: 0.2718"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 22s 86ms/step - loss: 0.2717 - val_loss: 0.2658\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2627 - val_loss: 0.2675\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2624 - val_loss: 0.2682\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2624 - val_loss: 0.2666\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 9s 70ms/step - loss: 0.2622 - val_loss: 0.2691\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2623 - val_loss: 0.2669\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2621 - val_loss: 0.2669\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 8s 69ms/step - loss: 0.2621 - val_loss: 0.2653\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2620 - val_loss: 0.2649\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2619 - val_loss: 0.2645\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2621 - val_loss: 0.2648\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 9s 70ms/step - loss: 0.2620 - val_loss: 0.2659\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2617 - val_loss: 0.2664\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2619 - val_loss: 0.2635\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 8s 69ms/step - loss: 0.2621 - val_loss: 0.2654\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 9s 75ms/step - loss: 0.2618 - val_loss: 0.2648\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 8s 67ms/step - loss: 0.2620 - val_loss: 0.2651\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2618 - val_loss: 0.2651\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 9s 70ms/step - loss: 0.2616 - val_loss: 0.2653\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 8s 67ms/step - loss: 0.2617 - val_loss: 0.2630\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 8s 69ms/step - loss: 0.2616 - val_loss: 0.2639\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2617 - val_loss: 0.2644\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 8s 67ms/step - loss: 0.2618 - val_loss: 0.2662\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 9s 70ms/step - loss: 0.2617 - val_loss: 0.2674\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 8s 69ms/step - loss: 0.2618 - val_loss: 0.2653\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 8s 68ms/step - loss: 0.2616 - val_loss: 0.2646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2619"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 8s 942ms/step - loss: 0.2619 - val_loss: 0.2645\n",
            "Epoch 2/13\n",
            "7/7 [==============================] - 8s 933ms/step - loss: 0.2615 - val_loss: 0.2660\n",
            "Epoch 3/13\n",
            "7/7 [==============================] - 8s 932ms/step - loss: 0.2613 - val_loss: 0.2649\n",
            "Epoch 4/13\n",
            "7/7 [==============================] - 8s 945ms/step - loss: 0.2611 - val_loss: 0.2645\n",
            "Epoch 5/13\n",
            "7/7 [==============================] - 8s 938ms/step - loss: 0.2610 - val_loss: 0.2651\n",
            "Epoch 6/13\n",
            "7/7 [==============================] - 8s 929ms/step - loss: 0.2610 - val_loss: 0.2652\n",
            "Epoch 7/13\n",
            "7/7 [==============================] - 8s 922ms/step - loss: 0.2609 - val_loss: 0.2644\n",
            "Epoch 8/13\n",
            "7/7 [==============================] - 8s 946ms/step - loss: 0.2610 - val_loss: 0.2645\n",
            "Epoch 9/13\n",
            "7/7 [==============================] - 8s 953ms/step - loss: 0.2609 - val_loss: 0.2647\n",
            "Epoch 10/13\n",
            "7/7 [==============================] - 8s 957ms/step - loss: 0.2609 - val_loss: 0.2647\n",
            "Epoch 11/13\n",
            "7/7 [==============================] - 8s 954ms/step - loss: 0.2608 - val_loss: 0.2648\n",
            "Epoch 12/13\n",
            "7/7 [==============================] - 8s 930ms/step - loss: 0.2607 - val_loss: 0.2645\n",
            "Epoch 13/13\n",
            "7/7 [==============================] - 8s 947ms/step - loss: 0.2609 - val_loss: 0.2644\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 21ms/step\n",
            "31/31 [==============================] - 1s 21ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇█▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄▆▇▅█▅▅▄▃▃▃▄▅▂▄▃▃▃▄▁▂▃▅▆▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄▆▇▅█▅▅▄▃▃▃▄▅▂▄▃▃▃▄▁▂▃▅▆▄▃▃▄▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2899</td></tr><tr><td>test_auc_score</td><td>0.61337</td></tr><tr><td>test_brier_loss</td><td>0.07098</td></tr><tr><td>test_mae</td><td>0.14874</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40593</td></tr><tr><td>test_mse</td><td>0.0797</td></tr><tr><td>train/epoch_loss</td><td>0.26087</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61975</td></tr><tr><td>train_brier_loss</td><td>0.07011</td></tr><tr><td>train_mae</td><td>0.14798</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40222</td></tr><tr><td>train_mse</td><td>0.07964</td></tr><tr><td>val_auc_score</td><td>0.60848</td></tr><tr><td>val_brier_loss</td><td>0.06998</td></tr><tr><td>val_mae</td><td>0.14783</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40607</td></tr><tr><td>val_mse</td><td>0.07992</td></tr><tr><td>validation/epoch_loss</td><td>0.26439</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26439</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-19-53-22</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zmwhp50a' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zmwhp50a</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_195325-zmwhp50a/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zvagdcml with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.6\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_200020-zvagdcml</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zvagdcml' target=\"_blank\">NN Train - 2023-05-29-20-00-17</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zvagdcml' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zvagdcml</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "216/216 [==============================] - 3s 6ms/step - loss: 0.3050 - val_loss: 0.2685\n",
            "Epoch 2/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2732 - val_loss: 0.2674\n",
            "Epoch 3/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2697 - val_loss: 0.2669\n",
            "Epoch 4/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2686 - val_loss: 0.2669\n",
            "Epoch 5/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2680 - val_loss: 0.2682\n",
            "Epoch 6/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2676 - val_loss: 0.2703\n",
            "Epoch 7/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2670 - val_loss: 0.2707\n",
            "Epoch 8/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2667 - val_loss: 0.2728\n",
            "Epoch 9/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2666 - val_loss: 0.2724\n",
            "Epoch 10/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2665 - val_loss: 0.2703\n",
            "Epoch 11/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2660 - val_loss: 0.2746\n",
            "Epoch 12/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2660 - val_loss: 0.2729\n",
            "Epoch 13/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2656 - val_loss: 0.2741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "215/216 [============================>.] - ETA: 0s - loss: 0.2906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 23s 46ms/step - loss: 0.2906 - val_loss: 0.2842\n",
            "Epoch 2/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2710 - val_loss: 0.2803\n",
            "Epoch 3/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2676 - val_loss: 0.2833\n",
            "Epoch 4/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2664 - val_loss: 0.2885\n",
            "Epoch 5/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2659 - val_loss: 0.2871\n",
            "Epoch 6/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2657 - val_loss: 0.2936\n",
            "Epoch 7/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2653 - val_loss: 0.2883\n",
            "Epoch 8/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2651 - val_loss: 0.2890\n",
            "Epoch 9/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2651 - val_loss: 0.2910\n",
            "Epoch 10/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2651 - val_loss: 0.2984\n",
            "Epoch 11/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2649 - val_loss: 0.2914\n",
            "Epoch 12/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2649 - val_loss: 0.3040\n",
            "Epoch 13/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2649 - val_loss: 0.2850\n",
            "Epoch 14/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2644 - val_loss: 0.3002\n",
            "Epoch 15/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2645 - val_loss: 0.2892\n",
            "Epoch 16/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2645 - val_loss: 0.2934\n",
            "Epoch 17/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2646 - val_loss: 0.2989\n",
            "Epoch 18/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2644 - val_loss: 0.3028\n",
            "Epoch 19/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2643 - val_loss: 0.2929\n",
            "Epoch 20/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2643 - val_loss: 0.2891\n",
            "Epoch 21/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2643 - val_loss: 0.3008\n",
            "Epoch 22/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2641 - val_loss: 0.3026\n",
            "Epoch 23/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2641 - val_loss: 0.3048\n",
            "Epoch 24/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2640 - val_loss: 0.3072\n",
            "Epoch 25/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2642 - val_loss: 0.2934\n",
            "Epoch 26/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2640 - val_loss: 0.2892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 5s 252ms/step - loss: 0.2637 - val_loss: 0.2944\n",
            "Epoch 2/13\n",
            "14/14 [==============================] - 5s 244ms/step - loss: 0.2635 - val_loss: 0.2958\n",
            "Epoch 3/13\n",
            "14/14 [==============================] - 5s 263ms/step - loss: 0.2634 - val_loss: 0.2976\n",
            "Epoch 4/13\n",
            "14/14 [==============================] - 5s 245ms/step - loss: 0.2633 - val_loss: 0.2955\n",
            "Epoch 5/13\n",
            "14/14 [==============================] - 5s 240ms/step - loss: 0.2632 - val_loss: 0.2962\n",
            "Epoch 6/13\n",
            "14/14 [==============================] - 5s 261ms/step - loss: 0.2633 - val_loss: 0.2932\n",
            "Epoch 7/13\n",
            "14/14 [==============================] - 5s 239ms/step - loss: 0.2631 - val_loss: 0.2965\n",
            "Epoch 8/13\n",
            "14/14 [==============================] - 5s 241ms/step - loss: 0.2632 - val_loss: 0.2980\n",
            "Epoch 9/13\n",
            "14/14 [==============================] - 5s 251ms/step - loss: 0.2630 - val_loss: 0.2974\n",
            "Epoch 10/13\n",
            "14/14 [==============================] - 5s 241ms/step - loss: 0.2630 - val_loss: 0.2982\n",
            "Epoch 11/13\n",
            "14/14 [==============================] - 5s 246ms/step - loss: 0.2630 - val_loss: 0.2990\n",
            "Epoch 12/13\n",
            "14/14 [==============================] - 5s 242ms/step - loss: 0.2632 - val_loss: 0.2988\n",
            "Epoch 13/13\n",
            "14/14 [==============================] - 5s 241ms/step - loss: 0.2629 - val_loss: 0.2970\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 14ms/step\n",
            "31/31 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇██▁▁▁▂▂▂▂▃▃▃▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▂▁▂▃▃▄▃▃▄▆▄▇▂▆▃▄▆▇▄▃▆▇▇█▄▃▅▅▅▅▅▄▅▆▅▆▆▆▅</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▂▁▂▃▃▄▃▃▄▆▄▇▂▆▃▄▆▇▄▃▆▇▇█▄▃▅▅▅▅▅▄▅▆▅▆▆▆▅</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▆▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>5798</td></tr><tr><td>test_auc_score</td><td>0.60959</td></tr><tr><td>test_brier_loss</td><td>0.08112</td></tr><tr><td>test_mae</td><td>0.19932</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.46586</td></tr><tr><td>test_mse</td><td>0.10457</td></tr><tr><td>train/epoch_loss</td><td>0.26295</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61408</td></tr><tr><td>train_brier_loss</td><td>0.0801</td></tr><tr><td>train_mae</td><td>0.19843</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.46192</td></tr><tr><td>train_mse</td><td>0.10405</td></tr><tr><td>val_auc_score</td><td>0.60767</td></tr><tr><td>val_brier_loss</td><td>0.07998</td></tr><tr><td>val_mae</td><td>0.19809</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.4659</td></tr><tr><td>val_mse</td><td>0.10538</td></tr><tr><td>validation/epoch_loss</td><td>0.29704</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.29704</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-00-17</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zvagdcml' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zvagdcml</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_200020-zvagdcml/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0xcjdw7r with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_200640-0xcjdw7r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/0xcjdw7r' target=\"_blank\">NN Train - 2023-05-29-20-06-37</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/0xcjdw7r' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/0xcjdw7r</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 4s 6ms/step - loss: 0.2700 - val_loss: 0.2680\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2644 - val_loss: 0.2675\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2637 - val_loss: 0.2657\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2635 - val_loss: 0.2661\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2632 - val_loss: 0.2667\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2632 - val_loss: 0.2628\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2631 - val_loss: 0.2639\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2628 - val_loss: 0.2645\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2629 - val_loss: 0.2662\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2627 - val_loss: 0.2665\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2627 - val_loss: 0.2671\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2627 - val_loss: 0.2640\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2625 - val_loss: 0.2656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2933"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 40ms/step - loss: 0.2933 - val_loss: 0.2965\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2686 - val_loss: 0.2702\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2651 - val_loss: 0.2714\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2637 - val_loss: 0.2645\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2629 - val_loss: 0.2664\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2629 - val_loss: 0.2657\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2629 - val_loss: 0.2710\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2627 - val_loss: 0.2677\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2628 - val_loss: 0.2684\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2640\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2624 - val_loss: 0.2644\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2625 - val_loss: 0.2679\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2624 - val_loss: 0.2667\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2625 - val_loss: 0.2653\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2646\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2659\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2624 - val_loss: 0.2660\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2622 - val_loss: 0.2665\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2623 - val_loss: 0.2731\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2709\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2656\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2622 - val_loss: 0.2709\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2637\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2621 - val_loss: 0.2656\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2622 - val_loss: 0.2696\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2622 - val_loss: 0.2663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2614"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 9s 132ms/step - loss: 0.2614 - val_loss: 0.2658\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 8s 128ms/step - loss: 0.2612 - val_loss: 0.2657\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 8s 130ms/step - loss: 0.2612 - val_loss: 0.2667\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 8s 129ms/step - loss: 0.2610 - val_loss: 0.2681\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 8s 126ms/step - loss: 0.2610 - val_loss: 0.2674\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 8s 129ms/step - loss: 0.2612 - val_loss: 0.2663\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 8s 127ms/step - loss: 0.2611 - val_loss: 0.2678\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 8s 127ms/step - loss: 0.2611 - val_loss: 0.2661\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 8s 129ms/step - loss: 0.2609 - val_loss: 0.2670\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 8s 127ms/step - loss: 0.2611 - val_loss: 0.2654\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 8s 129ms/step - loss: 0.2610 - val_loss: 0.2672\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 8s 130ms/step - loss: 0.2609 - val_loss: 0.2702\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 8s 126ms/step - loss: 0.2610 - val_loss: 0.2674\n",
            "216/216 [==============================] - 6s 21ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▃▄▄▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▂▃▁▂▁▃▂▂▁▁▂▂▁▁▁▂▂▃▃▁▃▁▁▂▂▁▁▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▂▃▁▂▁▃▂▂▁▁▂▂▁▁▁▂▂▃▃▁▃▁▁▂▂▁▁▂▂▂▂▂▂▂▁▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11908</td></tr><tr><td>test_auc_score</td><td>0.61366</td></tr><tr><td>test_brier_loss</td><td>0.07151</td></tr><tr><td>test_mae</td><td>0.14669</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4122</td></tr><tr><td>test_mse</td><td>0.08081</td></tr><tr><td>train/epoch_loss</td><td>0.26098</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61934</td></tr><tr><td>train_brier_loss</td><td>0.07061</td></tr><tr><td>train_mae</td><td>0.14592</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40812</td></tr><tr><td>train_mse</td><td>0.08066</td></tr><tr><td>val_auc_score</td><td>0.60846</td></tr><tr><td>val_brier_loss</td><td>0.07049</td></tr><tr><td>val_mae</td><td>0.14576</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.4128</td></tr><tr><td>val_mse</td><td>0.08103</td></tr><tr><td>validation/epoch_loss</td><td>0.26738</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26738</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-06-37</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/0xcjdw7r' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/0xcjdw7r</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_200640-0xcjdw7r/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rirzftn5 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_201710-rirzftn5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rirzftn5' target=\"_blank\">NN Train - 2023-05-29-20-17-08</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rirzftn5' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rirzftn5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "216/216 [==============================] - 3s 7ms/step - loss: 0.2820 - val_loss: 0.2836\n",
            "Epoch 2/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2776 - val_loss: 0.2805\n",
            "Epoch 3/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2767 - val_loss: 0.2781\n",
            "Epoch 4/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2764 - val_loss: 0.2775\n",
            "Epoch 5/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2786\n",
            "Epoch 6/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2763 - val_loss: 0.2773\n",
            "Epoch 7/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2786\n",
            "Epoch 8/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2760 - val_loss: 0.2780\n",
            "Epoch 9/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2794\n",
            "Epoch 10/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2786\n",
            "Epoch 11/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2789\n",
            "Epoch 12/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2759 - val_loss: 0.2776\n",
            "Epoch 13/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2758 - val_loss: 0.2777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "215/216 [============================>.] - ETA: 0s - loss: 0.3833"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 23s 47ms/step - loss: 0.3831 - val_loss: 0.2861\n",
            "Epoch 2/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2801 - val_loss: 0.2825\n",
            "Epoch 3/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2800 - val_loss: 0.2805\n",
            "Epoch 4/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2792 - val_loss: 0.2834\n",
            "Epoch 5/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2779 - val_loss: 0.2828\n",
            "Epoch 6/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2778 - val_loss: 0.2781\n",
            "Epoch 7/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2773 - val_loss: 0.2810\n",
            "Epoch 8/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2768 - val_loss: 0.2804\n",
            "Epoch 9/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2764 - val_loss: 0.2793\n",
            "Epoch 10/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2765 - val_loss: 0.2777\n",
            "Epoch 11/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2762 - val_loss: 0.2807\n",
            "Epoch 12/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2761 - val_loss: 0.2778\n",
            "Epoch 13/26\n",
            "216/216 [==============================] - 8s 35ms/step - loss: 0.2758 - val_loss: 0.2786\n",
            "Epoch 14/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2761 - val_loss: 0.2794\n",
            "Epoch 15/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2759 - val_loss: 0.2783\n",
            "Epoch 16/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2759 - val_loss: 0.2798\n",
            "Epoch 17/26\n",
            "216/216 [==============================] - 8s 35ms/step - loss: 0.2760 - val_loss: 0.2786\n",
            "Epoch 18/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2758 - val_loss: 0.2785\n",
            "Epoch 19/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2759 - val_loss: 0.2776\n",
            "Epoch 20/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2758 - val_loss: 0.2787\n",
            "Epoch 21/26\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2757 - val_loss: 0.2782\n",
            "Epoch 22/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2756 - val_loss: 0.2779\n",
            "Epoch 23/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2755 - val_loss: 0.2780\n",
            "Epoch 24/26\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2755 - val_loss: 0.2801\n",
            "Epoch 25/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2755 - val_loss: 0.2786\n",
            "Epoch 26/26\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2756 - val_loss: 0.2780\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2754"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 5s 257ms/step - loss: 0.2754 - val_loss: 0.2779\n",
            "Epoch 2/13\n",
            "14/14 [==============================] - 5s 272ms/step - loss: 0.2749 - val_loss: 0.2784\n",
            "Epoch 3/13\n",
            "14/14 [==============================] - 5s 246ms/step - loss: 0.2749 - val_loss: 0.2779\n",
            "Epoch 4/13\n",
            "14/14 [==============================] - 5s 259ms/step - loss: 0.2749 - val_loss: 0.2781\n",
            "Epoch 5/13\n",
            "14/14 [==============================] - 5s 258ms/step - loss: 0.2747 - val_loss: 0.2780\n",
            "Epoch 6/13\n",
            "14/14 [==============================] - 5s 259ms/step - loss: 0.2746 - val_loss: 0.2782\n",
            "Epoch 7/13\n",
            "14/14 [==============================] - 5s 250ms/step - loss: 0.2748 - val_loss: 0.2778\n",
            "Epoch 8/13\n",
            "14/14 [==============================] - 5s 260ms/step - loss: 0.2747 - val_loss: 0.2782\n",
            "Epoch 9/13\n",
            "14/14 [==============================] - 5s 248ms/step - loss: 0.2747 - val_loss: 0.2781\n",
            "Epoch 10/13\n",
            "14/14 [==============================] - 5s 271ms/step - loss: 0.2747 - val_loss: 0.2780\n",
            "Epoch 11/13\n",
            "14/14 [==============================] - 5s 246ms/step - loss: 0.2747 - val_loss: 0.2781\n",
            "Epoch 12/13\n",
            "14/14 [==============================] - 5s 257ms/step - loss: 0.2746 - val_loss: 0.2781\n",
            "Epoch 13/13\n",
            "14/14 [==============================] - 5s 260ms/step - loss: 0.2747 - val_loss: 0.2781\n",
            "216/216 [==============================] - 5s 14ms/step\n",
            "63/63 [==============================] - 1s 15ms/step\n",
            "31/31 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▇▇▇██▁▁▂▂▂▂▂▃▃▄▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▅▃▆▅▁▄▃▂▁▄▁▂▂▂▃▂▂▁▂▁▁▁▃▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▅▃▆▅▁▄▃▂▁▄▁▂▂▂▃▂▂▁▂▁▁▁▃▂▁▁▂▁▁▁▂▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>5798</td></tr><tr><td>test_auc_score</td><td>0.61333</td></tr><tr><td>test_brier_loss</td><td>0.07077</td></tr><tr><td>test_mae</td><td>0.1488</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40382</td></tr><tr><td>test_mse</td><td>0.07935</td></tr><tr><td>train/epoch_loss</td><td>0.27472</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62219</td></tr><tr><td>train_brier_loss</td><td>0.06987</td></tr><tr><td>train_mae</td><td>0.14812</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39975</td></tr><tr><td>train_mse</td><td>0.07927</td></tr><tr><td>val_auc_score</td><td>0.60819</td></tr><tr><td>val_brier_loss</td><td>0.0698</td></tr><tr><td>val_mae</td><td>0.14805</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40395</td></tr><tr><td>val_mse</td><td>0.07959</td></tr><tr><td>validation/epoch_loss</td><td>0.27811</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27811</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-17-08</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rirzftn5' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rirzftn5</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_201710-rirzftn5/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: twdcbfz0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_202336-twdcbfz0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/twdcbfz0' target=\"_blank\">NN Train - 2023-05-29-20-23-33</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/twdcbfz0' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/twdcbfz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 7ms/step - loss: 0.2856 - val_loss: 0.2786\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2787 - val_loss: 0.2792\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2778 - val_loss: 0.2799\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2774 - val_loss: 0.2801\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2771 - val_loss: 0.2781\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2767 - val_loss: 0.2792\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2766 - val_loss: 0.2799\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2763 - val_loss: 0.2788\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2788\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2761 - val_loss: 0.2787\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2759 - val_loss: 0.2792\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2760 - val_loss: 0.2783\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2759 - val_loss: 0.2807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "107/108 [============================>.] - ETA: 0s - loss: 0.2843"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 20s 64ms/step - loss: 0.2842 - val_loss: 0.2816\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2771 - val_loss: 0.2785\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2771 - val_loss: 0.2821\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2768 - val_loss: 0.2811\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 6s 49ms/step - loss: 0.2766 - val_loss: 0.2785\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2763 - val_loss: 0.2784\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2763 - val_loss: 0.2814\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2762 - val_loss: 0.2784\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 6s 43ms/step - loss: 0.2760 - val_loss: 0.2788\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 6s 46ms/step - loss: 0.2758 - val_loss: 0.2842\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 6s 42ms/step - loss: 0.2759 - val_loss: 0.2774\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 6s 45ms/step - loss: 0.2757 - val_loss: 0.2779\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 6s 42ms/step - loss: 0.2757 - val_loss: 0.2787\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 6s 42ms/step - loss: 0.2756 - val_loss: 0.2779\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2758 - val_loss: 0.2781\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2758 - val_loss: 0.2778\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 6s 45ms/step - loss: 0.2757 - val_loss: 0.2781\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 5s 40ms/step - loss: 0.2758 - val_loss: 0.2778\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2756 - val_loss: 0.2812\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 5s 40ms/step - loss: 0.2757 - val_loss: 0.2788\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 6s 42ms/step - loss: 0.2755 - val_loss: 0.2780\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 5s 40ms/step - loss: 0.2755 - val_loss: 0.2805\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 6s 42ms/step - loss: 0.2755 - val_loss: 0.2787\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 5s 40ms/step - loss: 0.2756 - val_loss: 0.2777\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 6s 44ms/step - loss: 0.2755 - val_loss: 0.2781\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 5s 41ms/step - loss: 0.2754 - val_loss: 0.2796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 4s 376ms/step - loss: 0.2753 - val_loss: 0.2780\n",
            "Epoch 2/13\n",
            "7/7 [==============================] - 4s 414ms/step - loss: 0.2753 - val_loss: 0.2783\n",
            "Epoch 3/13\n",
            "7/7 [==============================] - 4s 356ms/step - loss: 0.2753 - val_loss: 0.2790\n",
            "Epoch 4/13\n",
            "7/7 [==============================] - 4s 377ms/step - loss: 0.2752 - val_loss: 0.2787\n",
            "Epoch 5/13\n",
            "7/7 [==============================] - 4s 411ms/step - loss: 0.2750 - val_loss: 0.2790\n",
            "Epoch 6/13\n",
            "7/7 [==============================] - 4s 374ms/step - loss: 0.2750 - val_loss: 0.2786\n",
            "Epoch 7/13\n",
            "7/7 [==============================] - 4s 360ms/step - loss: 0.2750 - val_loss: 0.2786\n",
            "Epoch 8/13\n",
            "7/7 [==============================] - 4s 390ms/step - loss: 0.2750 - val_loss: 0.2786\n",
            "Epoch 9/13\n",
            "7/7 [==============================] - 4s 361ms/step - loss: 0.2750 - val_loss: 0.2787\n",
            "Epoch 10/13\n",
            "7/7 [==============================] - 4s 377ms/step - loss: 0.2749 - val_loss: 0.2787\n",
            "Epoch 11/13\n",
            "7/7 [==============================] - 4s 394ms/step - loss: 0.2751 - val_loss: 0.2789\n",
            "Epoch 12/13\n",
            "7/7 [==============================] - 4s 370ms/step - loss: 0.2750 - val_loss: 0.2783\n",
            "Epoch 13/13\n",
            "7/7 [==============================] - 4s 369ms/step - loss: 0.2751 - val_loss: 0.2788\n",
            "216/216 [==============================] - 5s 16ms/step\n",
            "63/63 [==============================] - 1s 14ms/step\n",
            "31/31 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇██▁▁▁▂▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▅▂▆▅▂▂▅▂▂█▁▁▂▂▂▁▂▁▅▂▂▄▂▁▂▃▂▂▃▂▃▂▂▂▂▂▃▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▂▆▅▂▂▅▂▂█▁▁▂▂▂▁▂▁▅▂▂▄▂▁▂▃▂▂▃▂▃▂▂▂▂▂▃▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2899</td></tr><tr><td>test_auc_score</td><td>0.61375</td></tr><tr><td>test_brier_loss</td><td>0.07097</td></tr><tr><td>test_mae</td><td>0.15141</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40519</td></tr><tr><td>test_mse</td><td>0.07971</td></tr><tr><td>train/epoch_loss</td><td>0.27506</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.6202</td></tr><tr><td>train_brier_loss</td><td>0.0701</td></tr><tr><td>train_mae</td><td>0.15067</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40166</td></tr><tr><td>train_mse</td><td>0.07964</td></tr><tr><td>val_auc_score</td><td>0.60845</td></tr><tr><td>val_brier_loss</td><td>0.06999</td></tr><tr><td>val_mae</td><td>0.15062</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40544</td></tr><tr><td>val_mse</td><td>0.07995</td></tr><tr><td>validation/epoch_loss</td><td>0.2788</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.2788</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-23-33</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/twdcbfz0' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/twdcbfz0</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_202336-twdcbfz0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u1sg08sq with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_202848-u1sg08sq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/u1sg08sq' target=\"_blank\">NN Train - 2023-05-29-20-28-46</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/u1sg08sq' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/u1sg08sq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "216/216 [==============================] - 4s 7ms/step - loss: 0.3023 - val_loss: 0.2713\n",
            "Epoch 2/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2741 - val_loss: 0.2703\n",
            "Epoch 3/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2711 - val_loss: 0.2708\n",
            "Epoch 4/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2705 - val_loss: 0.2706\n",
            "Epoch 5/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2701 - val_loss: 0.2706\n",
            "Epoch 6/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2700 - val_loss: 0.2702\n",
            "Epoch 7/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2698 - val_loss: 0.2705\n",
            "Epoch 8/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2694 - val_loss: 0.2704\n",
            "Epoch 9/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2693 - val_loss: 0.2705\n",
            "Epoch 10/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2693 - val_loss: 0.2704\n",
            "Epoch 11/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2692 - val_loss: 0.2703\n",
            "Epoch 12/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2691 - val_loss: 0.2703\n",
            "Epoch 13/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2691 - val_loss: 0.2704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "215/216 [============================>.] - ETA: 0s - loss: 0.2899"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 24s 52ms/step - loss: 0.2898 - val_loss: 0.2717\n",
            "Epoch 2/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2731 - val_loss: 0.2713\n",
            "Epoch 3/26\n",
            "216/216 [==============================] - 11s 43ms/step - loss: 0.2706 - val_loss: 0.2716\n",
            "Epoch 4/26\n",
            "216/216 [==============================] - 10s 44ms/step - loss: 0.2696 - val_loss: 0.2730\n",
            "Epoch 5/26\n",
            "216/216 [==============================] - 11s 43ms/step - loss: 0.2693 - val_loss: 0.2720\n",
            "Epoch 6/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2691 - val_loss: 0.2741\n",
            "Epoch 7/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2690 - val_loss: 0.2741\n",
            "Epoch 8/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2688 - val_loss: 0.2712\n",
            "Epoch 9/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2690 - val_loss: 0.2719\n",
            "Epoch 10/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2686 - val_loss: 0.2711\n",
            "Epoch 11/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2688 - val_loss: 0.2711\n",
            "Epoch 12/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2686 - val_loss: 0.2708\n",
            "Epoch 13/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2686 - val_loss: 0.2713\n",
            "Epoch 14/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2686 - val_loss: 0.2712\n",
            "Epoch 15/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2685 - val_loss: 0.2714\n",
            "Epoch 16/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2685 - val_loss: 0.2704\n",
            "Epoch 17/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2684 - val_loss: 0.2716\n",
            "Epoch 18/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2684 - val_loss: 0.2740\n",
            "Epoch 19/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2685 - val_loss: 0.2705\n",
            "Epoch 20/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2684 - val_loss: 0.2710\n",
            "Epoch 21/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2683 - val_loss: 0.2706\n",
            "Epoch 22/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2684 - val_loss: 0.2708\n",
            "Epoch 23/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2683 - val_loss: 0.2718\n",
            "Epoch 24/26\n",
            "216/216 [==============================] - 10s 44ms/step - loss: 0.2682 - val_loss: 0.2710\n",
            "Epoch 25/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2682 - val_loss: 0.2709\n",
            "Epoch 26/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2681 - val_loss: 0.2719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2681"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 8s 431ms/step - loss: 0.2681 - val_loss: 0.2709\n",
            "Epoch 2/13\n",
            "14/14 [==============================] - 7s 424ms/step - loss: 0.2680 - val_loss: 0.2712\n",
            "Epoch 3/13\n",
            "14/14 [==============================] - 7s 421ms/step - loss: 0.2679 - val_loss: 0.2710\n",
            "Epoch 4/13\n",
            "14/14 [==============================] - 7s 427ms/step - loss: 0.2678 - val_loss: 0.2710\n",
            "Epoch 5/13\n",
            "14/14 [==============================] - 7s 434ms/step - loss: 0.2677 - val_loss: 0.2711\n",
            "Epoch 6/13\n",
            "14/14 [==============================] - 7s 431ms/step - loss: 0.2677 - val_loss: 0.2708\n",
            "Epoch 7/13\n",
            "14/14 [==============================] - 7s 430ms/step - loss: 0.2677 - val_loss: 0.2709\n",
            "Epoch 8/13\n",
            "14/14 [==============================] - 7s 442ms/step - loss: 0.2676 - val_loss: 0.2707\n",
            "Epoch 9/13\n",
            "14/14 [==============================] - 7s 420ms/step - loss: 0.2676 - val_loss: 0.2708\n",
            "Epoch 10/13\n",
            "14/14 [==============================] - 7s 430ms/step - loss: 0.2676 - val_loss: 0.2708\n",
            "Epoch 11/13\n",
            "14/14 [==============================] - 7s 423ms/step - loss: 0.2676 - val_loss: 0.2709\n",
            "Epoch 12/13\n",
            "14/14 [==============================] - 7s 419ms/step - loss: 0.2675 - val_loss: 0.2709\n",
            "Epoch 13/13\n",
            "14/14 [==============================] - 7s 431ms/step - loss: 0.2675 - val_loss: 0.2708\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 19ms/step\n",
            "31/31 [==============================] - 1s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄▃▃▆▄██▃▄▂▂▂▃▃▃▁▃█▁▂▁▂▄▂▂▄▂▃▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄▃▃▆▄██▃▄▂▂▂▃▃▃▁▃█▁▂▁▂▄▂▂▄▂▃▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>5798</td></tr><tr><td>test_auc_score</td><td>0.61264</td></tr><tr><td>test_brier_loss</td><td>0.07101</td></tr><tr><td>test_mae</td><td>0.1526</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4056</td></tr><tr><td>test_mse</td><td>0.07971</td></tr><tr><td>train/epoch_loss</td><td>0.26753</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61744</td></tr><tr><td>train_brier_loss</td><td>0.07021</td></tr><tr><td>train_mae</td><td>0.15197</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40266</td></tr><tr><td>train_mse</td><td>0.07974</td></tr><tr><td>val_auc_score</td><td>0.60644</td></tr><tr><td>val_brier_loss</td><td>0.07011</td></tr><tr><td>val_mae</td><td>0.15193</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40619</td></tr><tr><td>val_mse</td><td>0.08002</td></tr><tr><td>validation/epoch_loss</td><td>0.27078</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27078</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-28-46</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/u1sg08sq' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/u1sg08sq</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_202848-u1sg08sq/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ga3826e8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_203702-ga3826e8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ga3826e8' target=\"_blank\">NN Train - 2023-05-29-20-36-59</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ga3826e8' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ga3826e8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "216/216 [==============================] - 3s 6ms/step - loss: 0.2711 - val_loss: 0.2695\n",
            "Epoch 2/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2646 - val_loss: 0.2702\n",
            "Epoch 3/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2637 - val_loss: 0.2743\n",
            "Epoch 4/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2637 - val_loss: 0.2685\n",
            "Epoch 5/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2635 - val_loss: 0.2683\n",
            "Epoch 6/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2631 - val_loss: 0.2681\n",
            "Epoch 7/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2631 - val_loss: 0.2697\n",
            "Epoch 8/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2631 - val_loss: 0.2701\n",
            "Epoch 9/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2632 - val_loss: 0.2655\n",
            "Epoch 10/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2631 - val_loss: 0.2676\n",
            "Epoch 11/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2628 - val_loss: 0.2675\n",
            "Epoch 12/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2630 - val_loss: 0.2722\n",
            "Epoch 13/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2628 - val_loss: 0.2703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "216/216 [==============================] - ETA: 0s - loss: 0.3188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 24s 50ms/step - loss: 0.3188 - val_loss: 0.2917\n",
            "Epoch 2/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2677 - val_loss: 0.2798\n",
            "Epoch 3/26\n",
            "216/216 [==============================] - 10s 39ms/step - loss: 0.2656 - val_loss: 0.2723\n",
            "Epoch 4/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2649 - val_loss: 0.2705\n",
            "Epoch 5/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2640 - val_loss: 0.2712\n",
            "Epoch 6/26\n",
            "216/216 [==============================] - 10s 43ms/step - loss: 0.2635 - val_loss: 0.2680\n",
            "Epoch 7/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2636 - val_loss: 0.2700\n",
            "Epoch 8/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2631 - val_loss: 0.2655\n",
            "Epoch 9/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2633 - val_loss: 0.2695\n",
            "Epoch 10/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2630 - val_loss: 0.2653\n",
            "Epoch 11/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2628 - val_loss: 0.2655\n",
            "Epoch 12/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2629 - val_loss: 0.2713\n",
            "Epoch 13/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2628 - val_loss: 0.2674\n",
            "Epoch 14/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2629 - val_loss: 0.2660\n",
            "Epoch 15/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2627 - val_loss: 0.2690\n",
            "Epoch 16/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2625 - val_loss: 0.2685\n",
            "Epoch 17/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2625 - val_loss: 0.2679\n",
            "Epoch 18/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2625 - val_loss: 0.2653\n",
            "Epoch 19/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2626 - val_loss: 0.2697\n",
            "Epoch 20/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2626 - val_loss: 0.2659\n",
            "Epoch 21/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2626 - val_loss: 0.2676\n",
            "Epoch 22/26\n",
            "216/216 [==============================] - 10s 42ms/step - loss: 0.2626 - val_loss: 0.2745\n",
            "Epoch 23/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2627 - val_loss: 0.2639\n",
            "Epoch 24/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2625 - val_loss: 0.2669\n",
            "Epoch 25/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2626 - val_loss: 0.2667\n",
            "Epoch 26/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2625 - val_loss: 0.2640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 6s 186ms/step - loss: 0.2620 - val_loss: 0.2686\n",
            "Epoch 2/13\n",
            "27/27 [==============================] - 6s 182ms/step - loss: 0.2612 - val_loss: 0.2679\n",
            "Epoch 3/13\n",
            "27/27 [==============================] - 6s 180ms/step - loss: 0.2612 - val_loss: 0.2680\n",
            "Epoch 4/13\n",
            "27/27 [==============================] - 6s 183ms/step - loss: 0.2611 - val_loss: 0.2667\n",
            "Epoch 5/13\n",
            "27/27 [==============================] - 6s 178ms/step - loss: 0.2610 - val_loss: 0.2684\n",
            "Epoch 6/13\n",
            "27/27 [==============================] - 6s 183ms/step - loss: 0.2611 - val_loss: 0.2680\n",
            "Epoch 7/13\n",
            "27/27 [==============================] - 6s 180ms/step - loss: 0.2610 - val_loss: 0.2670\n",
            "Epoch 8/13\n",
            "27/27 [==============================] - 6s 184ms/step - loss: 0.2610 - val_loss: 0.2703\n",
            "Epoch 9/13\n",
            "27/27 [==============================] - 6s 178ms/step - loss: 0.2611 - val_loss: 0.2708\n",
            "Epoch 10/13\n",
            "27/27 [==============================] - 6s 180ms/step - loss: 0.2609 - val_loss: 0.2700\n",
            "Epoch 11/13\n",
            "27/27 [==============================] - 6s 173ms/step - loss: 0.2611 - val_loss: 0.2704\n",
            "Epoch 12/13\n",
            "27/27 [==============================] - 6s 178ms/step - loss: 0.2610 - val_loss: 0.2698\n",
            "Epoch 13/13\n",
            "27/27 [==============================] - 6s 179ms/step - loss: 0.2609 - val_loss: 0.2683\n",
            "216/216 [==============================] - 5s 16ms/step\n",
            "63/63 [==============================] - 1s 21ms/step\n",
            "31/31 [==============================] - 1s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▁▂▂▂▃▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▅▃▃▃▂▃▁▂▁▁▃▂▂▂▂▂▁▂▁▂▄▁▂▂▁▂▂▂▂▂▂▂▃▃▃▃▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▅▃▃▃▂▃▁▂▁▁▃▂▂▂▂▂▁▂▁▂▄▁▂▂▁▂▂▂▂▂▂▂▃▃▃▃▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>5967</td></tr><tr><td>test_auc_score</td><td>0.61392</td></tr><tr><td>test_brier_loss</td><td>0.07207</td></tr><tr><td>test_mae</td><td>0.1537</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4139</td></tr><tr><td>test_mse</td><td>0.08238</td></tr><tr><td>train/epoch_loss</td><td>0.26087</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61916</td></tr><tr><td>train_brier_loss</td><td>0.07114</td></tr><tr><td>train_mae</td><td>0.15284</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40995</td></tr><tr><td>train_mse</td><td>0.08228</td></tr><tr><td>val_auc_score</td><td>0.60898</td></tr><tr><td>val_brier_loss</td><td>0.07102</td></tr><tr><td>val_mae</td><td>0.15273</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41439</td></tr><tr><td>val_mse</td><td>0.08296</td></tr><tr><td>validation/epoch_loss</td><td>0.26827</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26827</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-36-59</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ga3826e8' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ga3826e8</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_203702-ga3826e8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rd7b8ibh with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_204403-rd7b8ibh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rd7b8ibh' target=\"_blank\">NN Train - 2023-05-29-20-44-00</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rd7b8ibh' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rd7b8ibh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 8ms/step - loss: 0.2311 - val_loss: 0.2310\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2242 - val_loss: 0.2277\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2225 - val_loss: 0.2264\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2220 - val_loss: 0.2268\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2216 - val_loss: 0.2290\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2215 - val_loss: 0.2345\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2213 - val_loss: 0.2262\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2213 - val_loss: 0.2278\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2261\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2283\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2280\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2208 - val_loss: 0.2280\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2207 - val_loss: 0.2293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "107/108 [============================>.] - ETA: 0s - loss: 0.2527"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 21s 70ms/step - loss: 0.2525 - val_loss: 0.2437\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2245 - val_loss: 0.2404\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 7s 53ms/step - loss: 0.2233 - val_loss: 0.2284\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2226 - val_loss: 0.2281\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2221 - val_loss: 0.2325\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 7s 52ms/step - loss: 0.2217 - val_loss: 0.2255\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2216 - val_loss: 0.2323\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2214 - val_loss: 0.2343\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 6s 49ms/step - loss: 0.2212 - val_loss: 0.2250\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2207 - val_loss: 0.2251\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 7s 54ms/step - loss: 0.2207 - val_loss: 0.2330\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2209 - val_loss: 0.2243\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 7s 51ms/step - loss: 0.2207 - val_loss: 0.2279\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2206 - val_loss: 0.2292\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2207 - val_loss: 0.2323\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 7s 52ms/step - loss: 0.2205 - val_loss: 0.2297\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2204 - val_loss: 0.2250\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 7s 51ms/step - loss: 0.2203 - val_loss: 0.2277\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2203 - val_loss: 0.2265\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 7s 51ms/step - loss: 0.2204 - val_loss: 0.2279\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2203 - val_loss: 0.2265\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2201 - val_loss: 0.2253\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2201 - val_loss: 0.2250\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2203 - val_loss: 0.2256\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 6s 48ms/step - loss: 0.2201 - val_loss: 0.2255\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 6s 47ms/step - loss: 0.2200 - val_loss: 0.2325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 5s 520ms/step - loss: 0.2200 - val_loss: 0.2252\n",
            "Epoch 2/13\n",
            "7/7 [==============================] - 5s 505ms/step - loss: 0.2198 - val_loss: 0.2261\n",
            "Epoch 3/13\n",
            "7/7 [==============================] - 5s 521ms/step - loss: 0.2196 - val_loss: 0.2300\n",
            "Epoch 4/13\n",
            "7/7 [==============================] - 5s 540ms/step - loss: 0.2195 - val_loss: 0.2269\n",
            "Epoch 5/13\n",
            "7/7 [==============================] - 5s 523ms/step - loss: 0.2193 - val_loss: 0.2276\n",
            "Epoch 6/13\n",
            "7/7 [==============================] - 5s 510ms/step - loss: 0.2194 - val_loss: 0.2278\n",
            "Epoch 7/13\n",
            "7/7 [==============================] - 5s 541ms/step - loss: 0.2193 - val_loss: 0.2268\n",
            "Epoch 8/13\n",
            "7/7 [==============================] - 5s 488ms/step - loss: 0.2193 - val_loss: 0.2274\n",
            "Epoch 9/13\n",
            "7/7 [==============================] - 5s 539ms/step - loss: 0.2192 - val_loss: 0.2282\n",
            "Epoch 10/13\n",
            "7/7 [==============================] - 5s 510ms/step - loss: 0.2192 - val_loss: 0.2276\n",
            "Epoch 11/13\n",
            "7/7 [==============================] - 5s 520ms/step - loss: 0.2192 - val_loss: 0.2278\n",
            "Epoch 12/13\n",
            "7/7 [==============================] - 5s 520ms/step - loss: 0.2193 - val_loss: 0.2276\n",
            "Epoch 13/13\n",
            "7/7 [==============================] - 5s 533ms/step - loss: 0.2192 - val_loss: 0.2275\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 17ms/step\n",
            "31/31 [==============================] - 1s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇███▁▁▂▂▂▂▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▇▂▂▄▁▄▅▁▁▄▁▂▃▄▃▁▂▂▂▂▁▁▁▁▄▁▂▃▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▇▂▂▄▁▄▅▁▁▄▁▂▃▄▃▁▂▂▂▂▁▁▁▁▄▁▂▃▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2899</td></tr><tr><td>test_auc_score</td><td>0.61185</td></tr><tr><td>test_brier_loss</td><td>0.07299</td></tr><tr><td>test_mae</td><td>0.16021</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.42069</td></tr><tr><td>test_mse</td><td>0.08424</td></tr><tr><td>train/epoch_loss</td><td>0.21923</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61837</td></tr><tr><td>train_brier_loss</td><td>0.07202</td></tr><tr><td>train_mae</td><td>0.15938</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.4162</td></tr><tr><td>train_mse</td><td>0.08412</td></tr><tr><td>val_auc_score</td><td>0.60812</td></tr><tr><td>val_brier_loss</td><td>0.07188</td></tr><tr><td>val_mae</td><td>0.15913</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.42082</td></tr><tr><td>val_mse</td><td>0.08462</td></tr><tr><td>validation/epoch_loss</td><td>0.2275</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.2275</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-44-00</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rd7b8ibh' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/rd7b8ibh</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_204403-rd7b8ibh/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qlirq78w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_204925-qlirq78w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/qlirq78w' target=\"_blank\">NN Train - 2023-05-29-20-49-21</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/qlirq78w' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/qlirq78w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "216/216 [==============================] - 4s 7ms/step - loss: 0.2699 - val_loss: 0.2666\n",
            "Epoch 2/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2635 - val_loss: 0.2644\n",
            "Epoch 3/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2629 - val_loss: 0.2646\n",
            "Epoch 4/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2629 - val_loss: 0.2640\n",
            "Epoch 5/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2627 - val_loss: 0.2648\n",
            "Epoch 6/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2628 - val_loss: 0.2631\n",
            "Epoch 7/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2626 - val_loss: 0.2633\n",
            "Epoch 8/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2624 - val_loss: 0.2630\n",
            "Epoch 9/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2626 - val_loss: 0.2637\n",
            "Epoch 10/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2622 - val_loss: 0.2631\n",
            "Epoch 11/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2623 - val_loss: 0.2636\n",
            "Epoch 12/13\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2623 - val_loss: 0.2642\n",
            "Epoch 13/13\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2622 - val_loss: 0.2631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "215/216 [============================>.] - ETA: 0s - loss: 305.0234"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 24s 48ms/step - loss: 304.7150 - val_loss: 0.2795\n",
            "Epoch 2/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2714 - val_loss: 0.2921\n",
            "Epoch 3/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2678 - val_loss: 0.2683\n",
            "Epoch 4/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2655 - val_loss: 0.2687\n",
            "Epoch 5/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2649 - val_loss: 0.2676\n",
            "Epoch 6/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2642 - val_loss: 0.2681\n",
            "Epoch 7/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2631 - val_loss: 0.2669\n",
            "Epoch 8/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2629 - val_loss: 0.2655\n",
            "Epoch 9/26\n",
            "216/216 [==============================] - 10s 39ms/step - loss: 0.2621 - val_loss: 0.2640\n",
            "Epoch 10/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2622 - val_loss: 0.2644\n",
            "Epoch 11/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2621 - val_loss: 0.2641\n",
            "Epoch 12/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2618 - val_loss: 0.2629\n",
            "Epoch 13/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2619 - val_loss: 0.2651\n",
            "Epoch 14/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2617 - val_loss: 0.2633\n",
            "Epoch 15/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2616 - val_loss: 0.2639\n",
            "Epoch 16/26\n",
            "216/216 [==============================] - 9s 39ms/step - loss: 0.2616 - val_loss: 0.2633\n",
            "Epoch 17/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2615 - val_loss: 0.2645\n",
            "Epoch 18/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2615 - val_loss: 0.2629\n",
            "Epoch 19/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2616 - val_loss: 0.2630\n",
            "Epoch 20/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2614 - val_loss: 0.2639\n",
            "Epoch 21/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2616 - val_loss: 0.2631\n",
            "Epoch 22/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2614 - val_loss: 0.2626\n",
            "Epoch 23/26\n",
            "216/216 [==============================] - 10s 40ms/step - loss: 0.2613 - val_loss: 0.2647\n",
            "Epoch 24/26\n",
            "216/216 [==============================] - 9s 38ms/step - loss: 0.2615 - val_loss: 0.2629\n",
            "Epoch 25/26\n",
            "216/216 [==============================] - 10s 39ms/step - loss: 0.2616 - val_loss: 0.2652\n",
            "Epoch 26/26\n",
            "216/216 [==============================] - 10s 41ms/step - loss: 0.2612 - val_loss: 0.2630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2611"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 6s 321ms/step - loss: 0.2611 - val_loss: 0.2635\n",
            "Epoch 2/13\n",
            "14/14 [==============================] - 5s 296ms/step - loss: 0.2607 - val_loss: 0.2627\n",
            "Epoch 3/13\n",
            "14/14 [==============================] - 5s 304ms/step - loss: 0.2606 - val_loss: 0.2629\n",
            "Epoch 4/13\n",
            "14/14 [==============================] - 6s 298ms/step - loss: 0.2605 - val_loss: 0.2629\n",
            "Epoch 5/13\n",
            "14/14 [==============================] - 5s 305ms/step - loss: 0.2605 - val_loss: 0.2628\n",
            "Epoch 6/13\n",
            "14/14 [==============================] - 6s 309ms/step - loss: 0.2604 - val_loss: 0.2628\n",
            "Epoch 7/13\n",
            "14/14 [==============================] - 5s 300ms/step - loss: 0.2604 - val_loss: 0.2628\n",
            "Epoch 8/13\n",
            "14/14 [==============================] - 6s 314ms/step - loss: 0.2604 - val_loss: 0.2627\n",
            "Epoch 9/13\n",
            "14/14 [==============================] - 5s 293ms/step - loss: 0.2603 - val_loss: 0.2629\n",
            "Epoch 10/13\n",
            "14/14 [==============================] - 5s 298ms/step - loss: 0.2604 - val_loss: 0.2629\n",
            "Epoch 11/13\n",
            "14/14 [==============================] - 5s 295ms/step - loss: 0.2605 - val_loss: 0.2635\n",
            "Epoch 12/13\n",
            "14/14 [==============================] - 5s 311ms/step - loss: 0.2604 - val_loss: 0.2630\n",
            "Epoch 13/13\n",
            "14/14 [==============================] - 5s 297ms/step - loss: 0.2604 - val_loss: 0.2628\n",
            "216/216 [==============================] - 5s 18ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇██▁▁▁▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▅█▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅█▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>5798</td></tr><tr><td>test_auc_score</td><td>0.61441</td></tr><tr><td>test_brier_loss</td><td>0.07064</td></tr><tr><td>test_mae</td><td>0.14705</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40245</td></tr><tr><td>test_mse</td><td>0.07915</td></tr><tr><td>train/epoch_loss</td><td>0.2604</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62349</td></tr><tr><td>train_brier_loss</td><td>0.06976</td></tr><tr><td>train_mae</td><td>0.14632</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39849</td></tr><tr><td>train_mse</td><td>0.0791</td></tr><tr><td>val_auc_score</td><td>0.60909</td></tr><tr><td>val_brier_loss</td><td>0.06967</td></tr><tr><td>val_mae</td><td>0.14632</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40261</td></tr><tr><td>val_mse</td><td>0.07939</td></tr><tr><td>validation/epoch_loss</td><td>0.26282</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26282</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-49-21</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/qlirq78w' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/qlirq78w</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_204925-qlirq78w/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j4nd208w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_205621-j4nd208w</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j4nd208w' target=\"_blank\">NN Train - 2023-05-29-20-56-18</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j4nd208w' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j4nd208w</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 4s 6ms/step - loss: 0.2767 - val_loss: 0.2764\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2713 - val_loss: 0.2744\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2700 - val_loss: 0.2748\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2696 - val_loss: 0.2775\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2692 - val_loss: 0.2780\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2691 - val_loss: 0.2780\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2689 - val_loss: 0.2741\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2688 - val_loss: 0.2788\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2688 - val_loss: 0.2776\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2688 - val_loss: 0.2766\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2688 - val_loss: 0.2734\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2685 - val_loss: 0.2736\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2686 - val_loss: 0.2732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2820"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 29s 38ms/step - loss: 0.2820 - val_loss: 0.2978\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2734 - val_loss: 0.2876\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2715 - val_loss: 0.2732\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2706 - val_loss: 0.2757\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2698 - val_loss: 0.2809\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2692 - val_loss: 0.2783\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2689 - val_loss: 0.2750\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2688 - val_loss: 0.2739\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2685 - val_loss: 0.2789\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2684 - val_loss: 0.2734\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2685 - val_loss: 0.2772\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2685 - val_loss: 0.2783\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2684 - val_loss: 0.2764\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2684 - val_loss: 0.2733\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2684 - val_loss: 0.2756\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2681 - val_loss: 0.2769\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2682 - val_loss: 0.2747\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2682 - val_loss: 0.2836\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2683 - val_loss: 0.2770\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2681 - val_loss: 0.2765\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2680 - val_loss: 0.2797\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2683 - val_loss: 0.2799\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2680 - val_loss: 0.2728\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2679 - val_loss: 0.2735\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2681 - val_loss: 0.2841\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2681 - val_loss: 0.2767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 6s 85ms/step - loss: 0.2677 - val_loss: 0.2799\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 6s 85ms/step - loss: 0.2674 - val_loss: 0.2801\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 6s 81ms/step - loss: 0.2672 - val_loss: 0.2783\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 5s 82ms/step - loss: 0.2673 - val_loss: 0.2768\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 5s 81ms/step - loss: 0.2672 - val_loss: 0.2794\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 6s 86ms/step - loss: 0.2673 - val_loss: 0.2768\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 5s 82ms/step - loss: 0.2673 - val_loss: 0.2793\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 5s 81ms/step - loss: 0.2673 - val_loss: 0.2792\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 6s 86ms/step - loss: 0.2672 - val_loss: 0.2814\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 5s 79ms/step - loss: 0.2672 - val_loss: 0.2792\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 6s 83ms/step - loss: 0.2671 - val_loss: 0.2795\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 5s 80ms/step - loss: 0.2672 - val_loss: 0.2819\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 5s 80ms/step - loss: 0.2671 - val_loss: 0.2788\n",
            "216/216 [==============================] - 5s 16ms/step\n",
            "63/63 [==============================] - 1s 16ms/step\n",
            "31/31 [==============================] - 1s 16ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██▁▁▁▂▂▂▃▃▃▄▄▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▅▁▂▃▃▂▁▃▁▂▃▂▁▂▂▂▄▂▂▃▃▁▁▄▂▃▃▃▂▃▂▃▃▃▃▃▄▃</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▅▁▂▃▃▂▁▃▁▂▃▂▁▂▂▂▄▂▂▃▃▁▁▄▂▃▃▃▂▃▂▃▃▃▃▃▄▃</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11908</td></tr><tr><td>test_auc_score</td><td>0.61227</td></tr><tr><td>test_brier_loss</td><td>0.07314</td></tr><tr><td>test_mae</td><td>0.15896</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.42285</td></tr><tr><td>test_mse</td><td>0.08432</td></tr><tr><td>train/epoch_loss</td><td>0.2671</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61826</td></tr><tr><td>train_brier_loss</td><td>0.07221</td></tr><tr><td>train_mae</td><td>0.15824</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41861</td></tr><tr><td>train_mse</td><td>0.08419</td></tr><tr><td>val_auc_score</td><td>0.60737</td></tr><tr><td>val_brier_loss</td><td>0.07215</td></tr><tr><td>val_mae</td><td>0.15805</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.42395</td></tr><tr><td>val_mse</td><td>0.08478</td></tr><tr><td>validation/epoch_loss</td><td>0.27882</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27882</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-20-56-18</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j4nd208w' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/j4nd208w</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_205621-j4nd208w/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g4pifn06 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_210649-g4pifn06</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g4pifn06' target=\"_blank\">NN Train - 2023-05-29-21-06-46</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g4pifn06' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g4pifn06</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "216/216 [==============================] - 3s 6ms/step - loss: 0.2694 - val_loss: 0.2660\n",
            "Epoch 2/7\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2637 - val_loss: 0.2642\n",
            "Epoch 3/7\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2630 - val_loss: 0.2630\n",
            "Epoch 4/7\n",
            "216/216 [==============================] - 1s 5ms/step - loss: 0.2629 - val_loss: 0.2643\n",
            "Epoch 5/7\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2626 - val_loss: 0.2672\n",
            "Epoch 6/7\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2626 - val_loss: 0.2634\n",
            "Epoch 7/7\n",
            "216/216 [==============================] - 1s 6ms/step - loss: 0.2626 - val_loss: 0.2654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "215/216 [============================>.] - ETA: 0s - loss: 0.2688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r216/216 [==============================] - 22s 43ms/step - loss: 0.2688 - val_loss: 0.2644\n",
            "Epoch 2/14\n",
            "216/216 [==============================] - 9s 37ms/step - loss: 0.2634 - val_loss: 0.2663\n",
            "Epoch 3/14\n",
            "216/216 [==============================] - 8s 33ms/step - loss: 0.2629 - val_loss: 0.2631\n",
            "Epoch 4/14\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2627 - val_loss: 0.2654\n",
            "Epoch 5/14\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2627 - val_loss: 0.2654\n",
            "Epoch 6/14\n",
            "216/216 [==============================] - 8s 33ms/step - loss: 0.2628 - val_loss: 0.2645\n",
            "Epoch 7/14\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2626 - val_loss: 0.2639\n",
            "Epoch 8/14\n",
            "216/216 [==============================] - 9s 36ms/step - loss: 0.2623 - val_loss: 0.2636\n",
            "Epoch 9/14\n",
            "216/216 [==============================] - 8s 33ms/step - loss: 0.2625 - val_loss: 0.2657\n",
            "Epoch 10/14\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2625 - val_loss: 0.2667\n",
            "Epoch 11/14\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2623 - val_loss: 0.2627\n",
            "Epoch 12/14\n",
            "216/216 [==============================] - 8s 33ms/step - loss: 0.2622 - val_loss: 0.2639\n",
            "Epoch 13/14\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2626 - val_loss: 0.2631\n",
            "Epoch 14/14\n",
            "216/216 [==============================] - 9s 35ms/step - loss: 0.2623 - val_loss: 0.2638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2615"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 5s 121ms/step - loss: 0.2615 - val_loss: 0.2636\n",
            "Epoch 2/7\n",
            "27/27 [==============================] - 4s 107ms/step - loss: 0.2611 - val_loss: 0.2628\n",
            "Epoch 3/7\n",
            "27/27 [==============================] - 5s 131ms/step - loss: 0.2610 - val_loss: 0.2635\n",
            "Epoch 4/7\n",
            "27/27 [==============================] - 4s 108ms/step - loss: 0.2610 - val_loss: 0.2632\n",
            "Epoch 5/7\n",
            "27/27 [==============================] - 4s 116ms/step - loss: 0.2610 - val_loss: 0.2632\n",
            "Epoch 6/7\n",
            "27/27 [==============================] - 4s 122ms/step - loss: 0.2608 - val_loss: 0.2634\n",
            "Epoch 7/7\n",
            "27/27 [==============================] - 4s 116ms/step - loss: 0.2609 - val_loss: 0.2633\n",
            "216/216 [==============================] - 4s 13ms/step\n",
            "63/63 [==============================] - 1s 16ms/step\n",
            "31/31 [==============================] - 1s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▃▃▃▃▃▂▂▂▂▂▃▂▂▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▆▆▆▇▇▇█▁▁▂▂▂▃▃▃▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄▇▂▆▆▄▃▂▆█▁▃▂▃▃▁▂▂▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄▇▂▆▆▄▃▂▆█▁▃▂▃▃▁▂▂▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>3213</td></tr><tr><td>test_auc_score</td><td>0.61413</td></tr><tr><td>test_brier_loss</td><td>0.07071</td></tr><tr><td>test_mae</td><td>0.14606</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40339</td></tr><tr><td>test_mse</td><td>0.07926</td></tr><tr><td>train/epoch_loss</td><td>0.26094</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61957</td></tr><tr><td>train_brier_loss</td><td>0.06989</td></tr><tr><td>train_mae</td><td>0.14539</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40028</td></tr><tr><td>train_mse</td><td>0.07929</td></tr><tr><td>val_auc_score</td><td>0.60743</td></tr><tr><td>val_brier_loss</td><td>0.06975</td></tr><tr><td>val_mae</td><td>0.14526</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40386</td></tr><tr><td>val_mse</td><td>0.07951</td></tr><tr><td>validation/epoch_loss</td><td>0.26334</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26334</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-06-46</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g4pifn06' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g4pifn06</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_210649-g4pifn06/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sfnumxjr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_211038-sfnumxjr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/sfnumxjr' target=\"_blank\">NN Train - 2023-05-29-21-10-36</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/sfnumxjr' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/sfnumxjr</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 4s 6ms/step - loss: 0.2823 - val_loss: 0.2785\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2771 - val_loss: 0.2774\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2764 - val_loss: 0.2776\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2761 - val_loss: 0.2773\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2758 - val_loss: 0.2776\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2758 - val_loss: 0.2779\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2758 - val_loss: 0.2776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "431/431 [==============================] - ETA: 0s - loss: 21.6012"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 27s 34ms/step - loss: 21.6012 - val_loss: 0.2819\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2831 - val_loss: 0.2881\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2794 - val_loss: 0.2786\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2775 - val_loss: 0.2809\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2765 - val_loss: 0.2777\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2761 - val_loss: 0.2775\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2759 - val_loss: 0.2772\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2759 - val_loss: 0.2772\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2758 - val_loss: 0.2773\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2757 - val_loss: 0.2777\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2757 - val_loss: 0.2775\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2756 - val_loss: 0.2776\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2755 - val_loss: 0.2772\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2755 - val_loss: 0.2770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2748"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 5s 119ms/step - loss: 0.2748 - val_loss: 0.2769\n",
            "Epoch 2/7\n",
            "27/27 [==============================] - 4s 124ms/step - loss: 0.2748 - val_loss: 0.2768\n",
            "Epoch 3/7\n",
            "27/27 [==============================] - 4s 111ms/step - loss: 0.2748 - val_loss: 0.2768\n",
            "Epoch 4/7\n",
            "27/27 [==============================] - 4s 111ms/step - loss: 0.2748 - val_loss: 0.2769\n",
            "Epoch 5/7\n",
            "27/27 [==============================] - 5s 127ms/step - loss: 0.2747 - val_loss: 0.2769\n",
            "Epoch 6/7\n",
            "27/27 [==============================] - 4s 110ms/step - loss: 0.2747 - val_loss: 0.2769\n",
            "Epoch 7/7\n",
            "27/27 [==============================] - 4s 108ms/step - loss: 0.2746 - val_loss: 0.2769\n",
            "216/216 [==============================] - 5s 15ms/step\n",
            "63/63 [==============================] - 1s 13ms/step\n",
            "31/31 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▄▅▅▆▆▇▇▇█▁▂▂▂▃▃▃▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄█▂▄▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄█▂▄▂▁▁▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>6223</td></tr><tr><td>test_auc_score</td><td>0.61416</td></tr><tr><td>test_brier_loss</td><td>0.07055</td></tr><tr><td>test_mae</td><td>0.14591</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40131</td></tr><tr><td>test_mse</td><td>0.07899</td></tr><tr><td>train/epoch_loss</td><td>0.27461</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.62155</td></tr><tr><td>train_brier_loss</td><td>0.06973</td></tr><tr><td>train_mae</td><td>0.1453</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39825</td></tr><tr><td>train_mse</td><td>0.07906</td></tr><tr><td>val_auc_score</td><td>0.60776</td></tr><tr><td>val_brier_loss</td><td>0.06958</td></tr><tr><td>val_mae</td><td>0.14519</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40135</td></tr><tr><td>val_mse</td><td>0.07925</td></tr><tr><td>validation/epoch_loss</td><td>0.27686</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27686</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-10-36</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/sfnumxjr' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/sfnumxjr</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_211038-sfnumxjr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nls9obm2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_211611-nls9obm2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/nls9obm2' target=\"_blank\">NN Train - 2023-05-29-21-16-08</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/nls9obm2' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/nls9obm2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 4s 6ms/step - loss: 0.2751 - val_loss: 0.2710\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2694 - val_loss: 0.2698\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2687 - val_loss: 0.2698\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2686 - val_loss: 0.2694\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2683 - val_loss: 0.2703\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2683 - val_loss: 0.2705\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2682 - val_loss: 0.2699\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2680 - val_loss: 0.2695\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2681 - val_loss: 0.2710\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2681 - val_loss: 0.2701\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2680 - val_loss: 0.2696\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2680 - val_loss: 0.2718\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2678 - val_loss: 0.2703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.5031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 28s 33ms/step - loss: 0.5031 - val_loss: 0.2751\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2731 - val_loss: 0.2747\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2708 - val_loss: 0.2720\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2697 - val_loss: 0.2708\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2689 - val_loss: 0.2708\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2685 - val_loss: 0.2712\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2683 - val_loss: 0.2711\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2682 - val_loss: 0.2694\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2680 - val_loss: 0.2700\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2679 - val_loss: 0.2694\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2680 - val_loss: 0.2691\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2680 - val_loss: 0.2694\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2678 - val_loss: 0.2688\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2678 - val_loss: 0.2695\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2677 - val_loss: 0.2705\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2678 - val_loss: 0.2708\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2677 - val_loss: 0.2703\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2676 - val_loss: 0.2688\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2677 - val_loss: 0.2693\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2676 - val_loss: 0.2689\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2676 - val_loss: 0.2714\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2676 - val_loss: 0.2690\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2676 - val_loss: 0.2710\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2675 - val_loss: 0.2689\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 13s 28ms/step - loss: 0.2674 - val_loss: 0.2693\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 13s 29ms/step - loss: 0.2675 - val_loss: 0.2693\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 5s 123ms/step - loss: 0.2670 - val_loss: 0.2692\n",
            "Epoch 2/13\n",
            "27/27 [==============================] - 4s 112ms/step - loss: 0.2666 - val_loss: 0.2689\n",
            "Epoch 3/13\n",
            "27/27 [==============================] - 4s 123ms/step - loss: 0.2668 - val_loss: 0.2688\n",
            "Epoch 4/13\n",
            "27/27 [==============================] - 4s 114ms/step - loss: 0.2666 - val_loss: 0.2692\n",
            "Epoch 5/13\n",
            "27/27 [==============================] - 4s 113ms/step - loss: 0.2665 - val_loss: 0.2690\n",
            "Epoch 6/13\n",
            "27/27 [==============================] - 4s 120ms/step - loss: 0.2666 - val_loss: 0.2690\n",
            "Epoch 7/13\n",
            "27/27 [==============================] - 4s 114ms/step - loss: 0.2665 - val_loss: 0.2692\n",
            "Epoch 8/13\n",
            "27/27 [==============================] - 4s 116ms/step - loss: 0.2665 - val_loss: 0.2692\n",
            "Epoch 9/13\n",
            "27/27 [==============================] - 5s 126ms/step - loss: 0.2665 - val_loss: 0.2691\n",
            "Epoch 10/13\n",
            "27/27 [==============================] - 4s 111ms/step - loss: 0.2665 - val_loss: 0.2689\n",
            "Epoch 11/13\n",
            "27/27 [==============================] - 4s 115ms/step - loss: 0.2665 - val_loss: 0.2691\n",
            "Epoch 12/13\n",
            "27/27 [==============================] - 4s 117ms/step - loss: 0.2665 - val_loss: 0.2693\n",
            "Epoch 13/13\n",
            "27/27 [==============================] - 4s 112ms/step - loss: 0.2665 - val_loss: 0.2692\n",
            "216/216 [==============================] - 4s 14ms/step\n",
            "63/63 [==============================] - 1s 16ms/step\n",
            "31/31 [==============================] - 0s 13ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>██▅▃▃▄▄▂▂▂▁▂▁▂▃▃▃▁▂▁▄▁▃▁▂▂▁▁▁▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>██▅▃▃▄▄▂▂▂▁▂▁▂▃▃▃▁▂▁▄▁▃▁▂▂▁▁▁▁▁▁▂▁▁▁▁▂▁</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11557</td></tr><tr><td>test_auc_score</td><td>0.61446</td></tr><tr><td>test_brier_loss</td><td>0.07066</td></tr><tr><td>test_mae</td><td>0.14572</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40278</td></tr><tr><td>test_mse</td><td>0.07918</td></tr><tr><td>train/epoch_loss</td><td>0.26649</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62207</td></tr><tr><td>train_brier_loss</td><td>0.0698</td></tr><tr><td>train_mae</td><td>0.14501</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39915</td></tr><tr><td>train_mse</td><td>0.07916</td></tr><tr><td>val_auc_score</td><td>0.60776</td></tr><tr><td>val_brier_loss</td><td>0.0697</td></tr><tr><td>val_mae</td><td>0.14494</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40316</td></tr><tr><td>val_mse</td><td>0.07944</td></tr><tr><td>validation/epoch_loss</td><td>0.26921</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26921</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-16-08</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/nls9obm2' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/nls9obm2</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_211611-nls9obm2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uu7mcycz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_212516-uu7mcycz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/uu7mcycz' target=\"_blank\">NN Train - 2023-05-29-21-25-13</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/uu7mcycz' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/uu7mcycz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2302 - val_loss: 0.2258\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2241 - val_loss: 0.2249\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2228 - val_loss: 0.2271\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2220 - val_loss: 0.2244\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2214 - val_loss: 0.2239\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2211 - val_loss: 0.2251\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2209 - val_loss: 0.2253\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2208 - val_loss: 0.2238\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2206 - val_loss: 0.2240\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2205 - val_loss: 0.2241\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2204 - val_loss: 0.2250\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2204 - val_loss: 0.2235\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2203 - val_loss: 0.2248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2297"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 39ms/step - loss: 0.2297 - val_loss: 0.2396\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2243 - val_loss: 0.2353\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2226 - val_loss: 0.2262\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 16s 33ms/step - loss: 0.2214 - val_loss: 0.2286\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2208 - val_loss: 0.2269\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 16s 33ms/step - loss: 0.2207 - val_loss: 0.2277\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2204 - val_loss: 0.2265\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2202 - val_loss: 0.2247\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2201 - val_loss: 0.2241\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2199 - val_loss: 0.2260\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2200 - val_loss: 0.2261\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 16s 33ms/step - loss: 0.2199 - val_loss: 0.2262\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2199 - val_loss: 0.2234\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2200 - val_loss: 0.2259\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2200 - val_loss: 0.2258\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2198 - val_loss: 0.2253\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2199 - val_loss: 0.2262\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2198 - val_loss: 0.2258\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2197 - val_loss: 0.2231\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 15s 34ms/step - loss: 0.2197 - val_loss: 0.2275\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2198 - val_loss: 0.2230\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2197 - val_loss: 0.2278\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2197 - val_loss: 0.2258\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2197 - val_loss: 0.2227\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2197 - val_loss: 0.2269\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2197 - val_loss: 0.2266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 6s 92ms/step - loss: 0.2194 - val_loss: 0.2250\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 6s 95ms/step - loss: 0.2192 - val_loss: 0.2245\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 6s 89ms/step - loss: 0.2192 - val_loss: 0.2248\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 6s 91ms/step - loss: 0.2192 - val_loss: 0.2249\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 6s 87ms/step - loss: 0.2192 - val_loss: 0.2243\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 6s 93ms/step - loss: 0.2191 - val_loss: 0.2242\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 6s 92ms/step - loss: 0.2191 - val_loss: 0.2244\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 6s 87ms/step - loss: 0.2191 - val_loss: 0.2249\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 6s 90ms/step - loss: 0.2191 - val_loss: 0.2244\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 6s 87ms/step - loss: 0.2191 - val_loss: 0.2261\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 6s 87ms/step - loss: 0.2191 - val_loss: 0.2246\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 6s 88ms/step - loss: 0.2191 - val_loss: 0.2244\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 6s 94ms/step - loss: 0.2192 - val_loss: 0.2249\n",
            "216/216 [==============================] - 5s 16ms/step\n",
            "63/63 [==============================] - 1s 17ms/step\n",
            "31/31 [==============================] - 1s 17ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇▇██▁▁▂▂▂▃▃▃▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▆▂▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▁▃▁▃▂▁▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▆▂▃▃▃▃▂▂▂▂▂▁▂▂▂▂▂▁▃▁▃▂▁▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▇▁▁▁▁█▁▁▁▁▁▁▁▁▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11908</td></tr><tr><td>test_auc_score</td><td>0.61266</td></tr><tr><td>test_brier_loss</td><td>0.07189</td></tr><tr><td>test_mae</td><td>0.1576</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41302</td></tr><tr><td>test_mse</td><td>0.08146</td></tr><tr><td>train/epoch_loss</td><td>0.21915</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.6197</td></tr><tr><td>train_brier_loss</td><td>0.07098</td></tr><tr><td>train_mae</td><td>0.15679</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40869</td></tr><tr><td>train_mse</td><td>0.08127</td></tr><tr><td>val_auc_score</td><td>0.60812</td></tr><tr><td>val_brier_loss</td><td>0.07093</td></tr><tr><td>val_mae</td><td>0.15676</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41336</td></tr><tr><td>val_mse</td><td>0.08175</td></tr><tr><td>validation/epoch_loss</td><td>0.22494</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22494</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-25-13</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/uu7mcycz' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/uu7mcycz</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_212516-uu7mcycz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: udigrr54 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_213527-udigrr54</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/udigrr54' target=\"_blank\">NN Train - 2023-05-29-21-35-24</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/udigrr54' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/udigrr54</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 12s 6ms/step - loss: 0.2853 - val_loss: 0.2818\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2793 - val_loss: 0.2814\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2785 - val_loss: 0.2830\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2777 - val_loss: 0.2800\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2773 - val_loss: 0.2826\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2769 - val_loss: 0.2840\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2769 - val_loss: 0.2821\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2766 - val_loss: 0.2805\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2766 - val_loss: 0.2834\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2765 - val_loss: 0.2838\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2765 - val_loss: 0.2848\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2764 - val_loss: 0.2830\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2763 - val_loss: 0.2882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 40ms/step - loss: 0.2879 - val_loss: 0.2878\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2773 - val_loss: 0.2864\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2771 - val_loss: 0.2898\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2770 - val_loss: 0.2838\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2769 - val_loss: 0.2869\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2769 - val_loss: 0.2863\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2768 - val_loss: 0.2839\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2767 - val_loss: 0.2881\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2766 - val_loss: 0.2829\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2764 - val_loss: 0.2854\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2763 - val_loss: 0.2826\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2764 - val_loss: 0.2861\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2763 - val_loss: 0.2838\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2762 - val_loss: 0.2859\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2761 - val_loss: 0.2877\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2760 - val_loss: 0.2912\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2761 - val_loss: 0.2889\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2761 - val_loss: 0.2846\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2761 - val_loss: 0.2824\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2760 - val_loss: 0.2831\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2760 - val_loss: 0.2845\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2759 - val_loss: 0.2885\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2760 - val_loss: 0.2836\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2760 - val_loss: 0.2831\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2758 - val_loss: 0.2850\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2758 - val_loss: 0.2908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2756"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 7s 107ms/step - loss: 0.2756 - val_loss: 0.2838\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 7s 106ms/step - loss: 0.2755 - val_loss: 0.2867\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 7s 103ms/step - loss: 0.2754 - val_loss: 0.2850\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 7s 105ms/step - loss: 0.2755 - val_loss: 0.2850\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 7s 103ms/step - loss: 0.2754 - val_loss: 0.2844\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 7s 118ms/step - loss: 0.2754 - val_loss: 0.2869\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 7s 101ms/step - loss: 0.2754 - val_loss: 0.2849\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 7s 103ms/step - loss: 0.2753 - val_loss: 0.2855\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 6s 99ms/step - loss: 0.2754 - val_loss: 0.2843\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 7s 102ms/step - loss: 0.2755 - val_loss: 0.2845\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 6s 99ms/step - loss: 0.2754 - val_loss: 0.2853\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 7s 103ms/step - loss: 0.2754 - val_loss: 0.2851\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 6s 100ms/step - loss: 0.2753 - val_loss: 0.2850\n",
            "216/216 [==============================] - 6s 21ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▁▂▂▂▂▃▃▃▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▅▄▇▂▅▄▂▆▁▃▁▄▂▄▅█▆▃▁▂▃▆▂▂▃█▂▄▃▃▃▅▃▄▃▃▃▃▃</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▄▇▂▅▄▂▆▁▃▁▄▂▄▅█▆▃▁▂▃▆▂▂▃█▂▄▃▃▃▅▃▄▃▃▃▃▃</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11908</td></tr><tr><td>test_auc_score</td><td>0.61238</td></tr><tr><td>test_brier_loss</td><td>0.07216</td></tr><tr><td>test_mae</td><td>0.1513</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41758</td></tr><tr><td>test_mse</td><td>0.08202</td></tr><tr><td>train/epoch_loss</td><td>0.27528</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61771</td></tr><tr><td>train_brier_loss</td><td>0.07128</td></tr><tr><td>train_mae</td><td>0.15056</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41349</td></tr><tr><td>train_mse</td><td>0.08192</td></tr><tr><td>val_auc_score</td><td>0.60784</td></tr><tr><td>val_brier_loss</td><td>0.07118</td></tr><tr><td>val_mae</td><td>0.15045</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41843</td></tr><tr><td>val_mse</td><td>0.08229</td></tr><tr><td>validation/epoch_loss</td><td>0.285</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.285</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-35-24</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/udigrr54' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/udigrr54</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_213527-udigrr54/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n8bnzc84 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_214610-n8bnzc84</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/n8bnzc84' target=\"_blank\">NN Train - 2023-05-29-21-46-06</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/n8bnzc84' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/n8bnzc84</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2721 - val_loss: 0.2658\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2662 - val_loss: 0.2679\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2649 - val_loss: 0.2694\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2640 - val_loss: 0.2687\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2636 - val_loss: 0.2675\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2632 - val_loss: 0.2655\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2630 - val_loss: 0.2666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2771"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 29s 39ms/step - loss: 0.2771 - val_loss: 0.2940\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2694 - val_loss: 0.2934\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2677 - val_loss: 0.2812\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2663 - val_loss: 0.2748\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2650 - val_loss: 0.2720\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2641 - val_loss: 0.2757\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2636 - val_loss: 0.2718\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 16s 33ms/step - loss: 0.2633 - val_loss: 0.2690\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2631 - val_loss: 0.2663\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2627 - val_loss: 0.2684\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2626 - val_loss: 0.2703\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2624 - val_loss: 0.2674\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 15s 33ms/step - loss: 0.2623 - val_loss: 0.2706\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2623 - val_loss: 0.2670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 6s 172ms/step - loss: 0.2620 - val_loss: 0.2678\n",
            "Epoch 2/7\n",
            "27/27 [==============================] - 6s 174ms/step - loss: 0.2616 - val_loss: 0.2670\n",
            "Epoch 3/7\n",
            "27/27 [==============================] - 6s 167ms/step - loss: 0.2614 - val_loss: 0.2674\n",
            "Epoch 4/7\n",
            "27/27 [==============================] - 6s 170ms/step - loss: 0.2613 - val_loss: 0.2676\n",
            "Epoch 5/7\n",
            "27/27 [==============================] - 6s 164ms/step - loss: 0.2614 - val_loss: 0.2680\n",
            "Epoch 6/7\n",
            "27/27 [==============================] - 6s 164ms/step - loss: 0.2612 - val_loss: 0.2674\n",
            "Epoch 7/7\n",
            "27/27 [==============================] - 6s 165ms/step - loss: 0.2613 - val_loss: 0.2677\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 21ms/step\n",
            "31/31 [==============================] - 1s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▄▄▅▅▅▆▆▆▇▇▇█▁▁▂▂▃▃▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>██▅▃▂▃▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>██▅▃▂▃▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>6223</td></tr><tr><td>test_auc_score</td><td>0.61211</td></tr><tr><td>test_brier_loss</td><td>0.07169</td></tr><tr><td>test_mae</td><td>0.15429</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41192</td></tr><tr><td>test_mse</td><td>0.08096</td></tr><tr><td>train/epoch_loss</td><td>0.26134</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61816</td></tr><tr><td>train_brier_loss</td><td>0.07082</td></tr><tr><td>train_mae</td><td>0.15354</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40798</td></tr><tr><td>train_mse</td><td>0.08086</td></tr><tr><td>val_auc_score</td><td>0.60826</td></tr><tr><td>val_brier_loss</td><td>0.07072</td></tr><tr><td>val_mae</td><td>0.15348</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41218</td></tr><tr><td>val_mse</td><td>0.08124</td></tr><tr><td>validation/epoch_loss</td><td>0.26767</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26767</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-46-06</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/n8bnzc84' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/n8bnzc84</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_214610-n8bnzc84/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zjemtrth with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 4\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_215202-zjemtrth</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zjemtrth' target=\"_blank\">NN Train - 2023-05-29-21-51-59</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zjemtrth' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zjemtrth</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2693 - val_loss: 0.2658\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2653 - val_loss: 0.2753\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2653 - val_loss: 0.2655\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2654 - val_loss: 0.2638\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2647 - val_loss: 0.2729\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2652 - val_loss: 0.2686\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2647 - val_loss: 0.2638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "430/431 [============================>.] - ETA: 0s - loss: 0.2726"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 39ms/step - loss: 0.2727 - val_loss: 0.2685\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2665 - val_loss: 0.2676\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2663 - val_loss: 0.2649\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2664 - val_loss: 0.2666\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2665 - val_loss: 0.2638\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2662 - val_loss: 0.2696\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2659 - val_loss: 0.2649\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2661 - val_loss: 0.2665\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2658 - val_loss: 0.2643\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2663 - val_loss: 0.2674\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2655 - val_loss: 0.2637\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2654 - val_loss: 0.2659\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2653 - val_loss: 0.2652\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 15s 34ms/step - loss: 0.2650 - val_loss: 0.2670\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "108/108 [==============================] - ETA: 0s - loss: 0.2623"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 8s 63ms/step - loss: 0.2623 - val_loss: 0.2627\n",
            "Epoch 2/7\n",
            "108/108 [==============================] - 8s 61ms/step - loss: 0.2616 - val_loss: 0.2629\n",
            "Epoch 3/7\n",
            "108/108 [==============================] - 7s 58ms/step - loss: 0.2615 - val_loss: 0.2636\n",
            "Epoch 4/7\n",
            "108/108 [==============================] - 8s 61ms/step - loss: 0.2614 - val_loss: 0.2644\n",
            "Epoch 5/7\n",
            "108/108 [==============================] - 7s 56ms/step - loss: 0.2614 - val_loss: 0.2642\n",
            "Epoch 6/7\n",
            "108/108 [==============================] - 8s 61ms/step - loss: 0.2614 - val_loss: 0.2638\n",
            "Epoch 7/7\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2614 - val_loss: 0.2640\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▄▄▄▄▄▄▄▄▄▄▃▃▃▂▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▂▃▃▃▄▄▅▅▅▆▆▇▇▇█▁▁▂▂▂▃▃▃▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▇▆▃▅▂█▃▅▃▆▂▄▄▅▁▁▂▃▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▇▆▃▅▂█▃▅▃▆▂▄▄▅▁▁▂▃▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>6790</td></tr><tr><td>test_auc_score</td><td>0.6119</td></tr><tr><td>test_brier_loss</td><td>0.07099</td></tr><tr><td>test_mae</td><td>0.15593</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40495</td></tr><tr><td>test_mse</td><td>0.07973</td></tr><tr><td>train/epoch_loss</td><td>0.26138</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61753</td></tr><tr><td>train_brier_loss</td><td>0.07016</td></tr><tr><td>train_mae</td><td>0.1552</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.402</td></tr><tr><td>train_mse</td><td>0.07972</td></tr><tr><td>val_auc_score</td><td>0.60515</td></tr><tr><td>val_brier_loss</td><td>0.07002</td></tr><tr><td>val_mae</td><td>0.15515</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40525</td></tr><tr><td>val_mse</td><td>0.08002</td></tr><tr><td>validation/epoch_loss</td><td>0.26397</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26397</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-51-59</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zjemtrth' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/zjemtrth</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_215202-zjemtrth/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ii20l0rf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_215833-ii20l0rf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ii20l0rf' target=\"_blank\">NN Train - 2023-05-29-21-58-30</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ii20l0rf' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ii20l0rf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 8ms/step - loss: 0.2356 - val_loss: 0.2281\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2247 - val_loss: 0.2259\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 8ms/step - loss: 0.2234 - val_loss: 0.2244\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.2227 - val_loss: 0.2248\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2223 - val_loss: 0.2225\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2220 - val_loss: 0.2235\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2218 - val_loss: 0.2240\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2214 - val_loss: 0.2229\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2211 - val_loss: 0.2219\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2220\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2214\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 5ms/step - loss: 0.2207 - val_loss: 0.2215\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2206 - val_loss: 0.2225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "107/108 [============================>.] - ETA: 0s - loss: 0.2439"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 22s 78ms/step - loss: 0.2438 - val_loss: 0.2232\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 7s 56ms/step - loss: 0.2245 - val_loss: 0.2234\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 8s 59ms/step - loss: 0.2224 - val_loss: 0.2243\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 8s 60ms/step - loss: 0.2216 - val_loss: 0.2245\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 7s 58ms/step - loss: 0.2211 - val_loss: 0.2242\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 7s 59ms/step - loss: 0.2208 - val_loss: 0.2237\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 8s 60ms/step - loss: 0.2206 - val_loss: 0.2229\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 7s 56ms/step - loss: 0.2206 - val_loss: 0.2233\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 8s 61ms/step - loss: 0.2204 - val_loss: 0.2231\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2202 - val_loss: 0.2223\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 8s 59ms/step - loss: 0.2202 - val_loss: 0.2238\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 7s 60ms/step - loss: 0.2202 - val_loss: 0.2225\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 7s 58ms/step - loss: 0.2199 - val_loss: 0.2229\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 8s 60ms/step - loss: 0.2201 - val_loss: 0.2214\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2199 - val_loss: 0.2227\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 7s 56ms/step - loss: 0.2199 - val_loss: 0.2228\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 8s 61ms/step - loss: 0.2199 - val_loss: 0.2228\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2197 - val_loss: 0.2220\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 8s 59ms/step - loss: 0.2199 - val_loss: 0.2214\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 7s 58ms/step - loss: 0.2198 - val_loss: 0.2222\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2197 - val_loss: 0.2222\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 8s 63ms/step - loss: 0.2198 - val_loss: 0.2229\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2196 - val_loss: 0.2218\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2197 - val_loss: 0.2223\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 7s 59ms/step - loss: 0.2196 - val_loss: 0.2219\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 7s 57ms/step - loss: 0.2196 - val_loss: 0.2224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "14/14 [==============================] - ETA: 0s - loss: 0.2194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r14/14 [==============================] - 6s 346ms/step - loss: 0.2194 - val_loss: 0.2222\n",
            "Epoch 2/13\n",
            "14/14 [==============================] - 6s 313ms/step - loss: 0.2194 - val_loss: 0.2223\n",
            "Epoch 3/13\n",
            "14/14 [==============================] - 6s 340ms/step - loss: 0.2193 - val_loss: 0.2220\n",
            "Epoch 4/13\n",
            "14/14 [==============================] - 6s 317ms/step - loss: 0.2194 - val_loss: 0.2221\n",
            "Epoch 5/13\n",
            "14/14 [==============================] - 6s 323ms/step - loss: 0.2193 - val_loss: 0.2219\n",
            "Epoch 6/13\n",
            "14/14 [==============================] - 6s 319ms/step - loss: 0.2192 - val_loss: 0.2221\n",
            "Epoch 7/13\n",
            "14/14 [==============================] - 6s 335ms/step - loss: 0.2192 - val_loss: 0.2220\n",
            "Epoch 8/13\n",
            "14/14 [==============================] - 6s 323ms/step - loss: 0.2192 - val_loss: 0.2219\n",
            "Epoch 9/13\n",
            "14/14 [==============================] - 6s 339ms/step - loss: 0.2192 - val_loss: 0.2219\n",
            "Epoch 10/13\n",
            "14/14 [==============================] - 6s 325ms/step - loss: 0.2193 - val_loss: 0.2219\n",
            "Epoch 11/13\n",
            "14/14 [==============================] - 6s 330ms/step - loss: 0.2193 - val_loss: 0.2218\n",
            "Epoch 12/13\n",
            "14/14 [==============================] - 6s 320ms/step - loss: 0.2192 - val_loss: 0.2218\n",
            "Epoch 13/13\n",
            "14/14 [==============================] - 6s 326ms/step - loss: 0.2193 - val_loss: 0.2218\n",
            "216/216 [==============================] - 5s 18ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 19ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▅▆▆▇▇▇▇███▁▁▂▂▂▂▃▃▃▄▄▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▅▆██▇▆▅▅▅▃▆▃▅▁▄▄▄▃▁▃▃▅▂▃▂▃▃▃▂▃▂▃▂▂▂▂▂▂▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▅▆██▇▆▅▅▅▃▆▃▅▁▄▄▄▃▁▃▃▅▂▃▂▃▃▃▂▃▂▃▂▂▂▂▂▂▂</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2990</td></tr><tr><td>test_auc_score</td><td>0.61395</td></tr><tr><td>test_brier_loss</td><td>0.07096</td></tr><tr><td>test_mae</td><td>0.15233</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40515</td></tr><tr><td>test_mse</td><td>0.07966</td></tr><tr><td>train/epoch_loss</td><td>0.21926</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61901</td></tr><tr><td>train_brier_loss</td><td>0.07012</td></tr><tr><td>train_mae</td><td>0.15167</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40197</td></tr><tr><td>train_mse</td><td>0.07965</td></tr><tr><td>val_auc_score</td><td>0.60841</td></tr><tr><td>val_brier_loss</td><td>0.06999</td></tr><tr><td>val_mae</td><td>0.15156</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40534</td></tr><tr><td>val_mse</td><td>0.07991</td></tr><tr><td>validation/epoch_loss</td><td>0.22182</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22182</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-21-58-30</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ii20l0rf' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/ii20l0rf</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_215833-ii20l0rf/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xja4xhm0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2048\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_220438-xja4xhm0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/xja4xhm0' target=\"_blank\">NN Train - 2023-05-29-22-04-36</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/xja4xhm0' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/xja4xhm0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "108/108 [==============================] - 3s 8ms/step - loss: 0.2334 - val_loss: 0.2351\n",
            "Epoch 2/13\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.2255 - val_loss: 0.2341\n",
            "Epoch 3/13\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.2239 - val_loss: 0.2287\n",
            "Epoch 4/13\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.2229 - val_loss: 0.2298\n",
            "Epoch 5/13\n",
            "108/108 [==============================] - 1s 7ms/step - loss: 0.2226 - val_loss: 0.2298\n",
            "Epoch 6/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2220 - val_loss: 0.2336\n",
            "Epoch 7/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2216 - val_loss: 0.2326\n",
            "Epoch 8/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2212 - val_loss: 0.2304\n",
            "Epoch 9/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2212 - val_loss: 0.2268\n",
            "Epoch 10/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2284\n",
            "Epoch 11/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2278\n",
            "Epoch 12/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2208 - val_loss: 0.2262\n",
            "Epoch 13/13\n",
            "108/108 [==============================] - 1s 6ms/step - loss: 0.2208 - val_loss: 0.2282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "108/108 [==============================] - ETA: 0s - loss: 0.2276"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/108 [==============================] - 25s 93ms/step - loss: 0.2276 - val_loss: 0.2309\n",
            "Epoch 2/26\n",
            "108/108 [==============================] - 9s 77ms/step - loss: 0.2221 - val_loss: 0.2388\n",
            "Epoch 3/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2219 - val_loss: 0.2328\n",
            "Epoch 4/26\n",
            "108/108 [==============================] - 9s 75ms/step - loss: 0.2213 - val_loss: 0.2266\n",
            "Epoch 5/26\n",
            "108/108 [==============================] - 9s 75ms/step - loss: 0.2212 - val_loss: 0.2326\n",
            "Epoch 6/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2208 - val_loss: 0.2285\n",
            "Epoch 7/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2208 - val_loss: 0.2307\n",
            "Epoch 8/26\n",
            "108/108 [==============================] - 9s 76ms/step - loss: 0.2206 - val_loss: 0.2297\n",
            "Epoch 9/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2204 - val_loss: 0.2273\n",
            "Epoch 10/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2202 - val_loss: 0.2350\n",
            "Epoch 11/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2203 - val_loss: 0.2292\n",
            "Epoch 12/26\n",
            "108/108 [==============================] - 9s 75ms/step - loss: 0.2203 - val_loss: 0.2323\n",
            "Epoch 13/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2201 - val_loss: 0.2266\n",
            "Epoch 14/26\n",
            "108/108 [==============================] - 9s 75ms/step - loss: 0.2201 - val_loss: 0.2302\n",
            "Epoch 15/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2202 - val_loss: 0.2278\n",
            "Epoch 16/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2199 - val_loss: 0.2293\n",
            "Epoch 17/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2200 - val_loss: 0.2259\n",
            "Epoch 18/26\n",
            "108/108 [==============================] - 9s 74ms/step - loss: 0.2200 - val_loss: 0.2295\n",
            "Epoch 19/26\n",
            "108/108 [==============================] - 8s 70ms/step - loss: 0.2200 - val_loss: 0.2285\n",
            "Epoch 20/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2199 - val_loss: 0.2316\n",
            "Epoch 21/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2200 - val_loss: 0.2308\n",
            "Epoch 22/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2200 - val_loss: 0.2291\n",
            "Epoch 23/26\n",
            "108/108 [==============================] - 9s 70ms/step - loss: 0.2199 - val_loss: 0.2282\n",
            "Epoch 24/26\n",
            "108/108 [==============================] - 9s 73ms/step - loss: 0.2199 - val_loss: 0.2322\n",
            "Epoch 25/26\n",
            "108/108 [==============================] - 9s 72ms/step - loss: 0.2199 - val_loss: 0.2273\n",
            "Epoch 26/26\n",
            "108/108 [==============================] - 9s 71ms/step - loss: 0.2200 - val_loss: 0.2261\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.2196"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 8s 992ms/step - loss: 0.2196 - val_loss: 0.2257\n",
            "Epoch 2/13\n",
            "7/7 [==============================] - 8s 948ms/step - loss: 0.2195 - val_loss: 0.2273\n",
            "Epoch 3/13\n",
            "7/7 [==============================] - 8s 981ms/step - loss: 0.2195 - val_loss: 0.2284\n",
            "Epoch 4/13\n",
            "7/7 [==============================] - 8s 941ms/step - loss: 0.2195 - val_loss: 0.2288\n",
            "Epoch 5/13\n",
            "7/7 [==============================] - 8s 995ms/step - loss: 0.2193 - val_loss: 0.2271\n",
            "Epoch 6/13\n",
            "7/7 [==============================] - 8s 952ms/step - loss: 0.2194 - val_loss: 0.2287\n",
            "Epoch 7/13\n",
            "7/7 [==============================] - 8s 983ms/step - loss: 0.2193 - val_loss: 0.2285\n",
            "Epoch 8/13\n",
            "7/7 [==============================] - 8s 958ms/step - loss: 0.2193 - val_loss: 0.2289\n",
            "Epoch 9/13\n",
            "7/7 [==============================] - 8s 962ms/step - loss: 0.2193 - val_loss: 0.2280\n",
            "Epoch 10/13\n",
            "7/7 [==============================] - 8s 960ms/step - loss: 0.2193 - val_loss: 0.2293\n",
            "Epoch 11/13\n",
            "7/7 [==============================] - 8s 980ms/step - loss: 0.2193 - val_loss: 0.2280\n",
            "Epoch 12/13\n",
            "7/7 [==============================] - 8s 985ms/step - loss: 0.2193 - val_loss: 0.2294\n",
            "Epoch 13/13\n",
            "7/7 [==============================] - 8s 983ms/step - loss: 0.2192 - val_loss: 0.2287\n",
            "216/216 [==============================] - 6s 21ms/step\n",
            "63/63 [==============================] - 1s 20ms/step\n",
            "31/31 [==============================] - 1s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▆▆▇▇▇▇██▁▁▂▂▂▃▃▃▄▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄█▅▁▅▃▄▃▂▆▃▅▁▃▂▃▁▃▃▄▄▃▂▅▂▁▁▂▂▃▂▃▂▃▂▃▂▃▃</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄█▅▁▅▃▄▃▂▆▃▅▁▃▂▃▁▃▃▄▄▃▂▅▂▁▁▂▂▃▂▃▂▃▂▃▂▃▃</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2899</td></tr><tr><td>test_auc_score</td><td>0.61262</td></tr><tr><td>test_brier_loss</td><td>0.07329</td></tr><tr><td>test_mae</td><td>0.16258</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.42299</td></tr><tr><td>test_mse</td><td>0.08472</td></tr><tr><td>train/epoch_loss</td><td>0.21921</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61803</td></tr><tr><td>train_brier_loss</td><td>0.07239</td></tr><tr><td>train_mae</td><td>0.16183</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41891</td></tr><tr><td>train_mse</td><td>0.08459</td></tr><tr><td>val_auc_score</td><td>0.60853</td></tr><tr><td>val_brier_loss</td><td>0.07226</td></tr><tr><td>val_mae</td><td>0.1616</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.42348</td></tr><tr><td>val_mse</td><td>0.08516</td></tr><tr><td>validation/epoch_loss</td><td>0.22874</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22874</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-04-36</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/xja4xhm0' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/xja4xhm0</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_220438-xja4xhm0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2l36l1wo with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_221138-2l36l1wo</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/2l36l1wo' target=\"_blank\">NN Train - 2023-05-29-22-11-36</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/2l36l1wo' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/2l36l1wo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2724 - val_loss: 0.2656\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2656 - val_loss: 0.2648\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2645 - val_loss: 0.2663\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2635 - val_loss: 0.2634\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2630 - val_loss: 0.2640\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2626 - val_loss: 0.2640\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2624 - val_loss: 0.2639\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2622 - val_loss: 0.2661\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2620 - val_loss: 0.2636\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2620 - val_loss: 0.2633\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2619 - val_loss: 0.2642\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2618 - val_loss: 0.2631\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2617 - val_loss: 0.2630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2661"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 28s 34ms/step - loss: 0.2661 - val_loss: 0.2650\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2624 - val_loss: 0.2639\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2624 - val_loss: 0.2640\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2621 - val_loss: 0.2633\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2619 - val_loss: 0.2644\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2619 - val_loss: 0.2638\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2618 - val_loss: 0.2629\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2615 - val_loss: 0.2628\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2616 - val_loss: 0.2646\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2615 - val_loss: 0.2644\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2614 - val_loss: 0.2630\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2614 - val_loss: 0.2634\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2614 - val_loss: 0.2636\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2612 - val_loss: 0.2642\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2613 - val_loss: 0.2651\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2614 - val_loss: 0.2636\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2613 - val_loss: 0.2633\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2612 - val_loss: 0.2635\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2613 - val_loss: 0.2631\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2612 - val_loss: 0.2638\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2612 - val_loss: 0.2629\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2613 - val_loss: 0.2630\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2612 - val_loss: 0.2633\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2611 - val_loss: 0.2648\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 14s 29ms/step - loss: 0.2612 - val_loss: 0.2642\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2612 - val_loss: 0.2636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2609"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 5s 75ms/step - loss: 0.2609 - val_loss: 0.2630\n",
            "Epoch 2/13\n",
            "54/54 [==============================] - 5s 66ms/step - loss: 0.2607 - val_loss: 0.2630\n",
            "Epoch 3/13\n",
            "54/54 [==============================] - 5s 67ms/step - loss: 0.2607 - val_loss: 0.2632\n",
            "Epoch 4/13\n",
            "54/54 [==============================] - 5s 77ms/step - loss: 0.2607 - val_loss: 0.2632\n",
            "Epoch 5/13\n",
            "54/54 [==============================] - 5s 65ms/step - loss: 0.2606 - val_loss: 0.2629\n",
            "Epoch 6/13\n",
            "54/54 [==============================] - 5s 65ms/step - loss: 0.2607 - val_loss: 0.2629\n",
            "Epoch 7/13\n",
            "54/54 [==============================] - 5s 72ms/step - loss: 0.2607 - val_loss: 0.2633\n",
            "Epoch 8/13\n",
            "54/54 [==============================] - 5s 63ms/step - loss: 0.2606 - val_loss: 0.2634\n",
            "Epoch 9/13\n",
            "54/54 [==============================] - 5s 68ms/step - loss: 0.2606 - val_loss: 0.2631\n",
            "Epoch 10/13\n",
            "54/54 [==============================] - 5s 62ms/step - loss: 0.2606 - val_loss: 0.2634\n",
            "Epoch 11/13\n",
            "54/54 [==============================] - 5s 65ms/step - loss: 0.2606 - val_loss: 0.2633\n",
            "Epoch 12/13\n",
            "54/54 [==============================] - 5s 74ms/step - loss: 0.2606 - val_loss: 0.2628\n",
            "Epoch 13/13\n",
            "54/54 [==============================] - 5s 65ms/step - loss: 0.2606 - val_loss: 0.2633\n",
            "216/216 [==============================] - 5s 14ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇█████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▇▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▅▅▃▆▄▂▁▇▆▂▃▃▅█▄▃▃▂▄▁▂▃▇▅▄▂▂▂▂▁▂▃▃▂▃▃▁▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▅▅▃▆▄▂▁▇▆▂▃▃▅█▄▃▃▂▄▁▂▃▇▅▄▂▂▂▂▁▂▃▃▂▃▃▁▂</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11908</td></tr><tr><td>test_auc_score</td><td>0.61396</td></tr><tr><td>test_brier_loss</td><td>0.07074</td></tr><tr><td>test_mae</td><td>0.14961</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40332</td></tr><tr><td>test_mse</td><td>0.07931</td></tr><tr><td>train/epoch_loss</td><td>0.26064</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62137</td></tr><tr><td>train_brier_loss</td><td>0.06988</td></tr><tr><td>train_mae</td><td>0.14889</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39978</td></tr><tr><td>train_mse</td><td>0.07928</td></tr><tr><td>val_auc_score</td><td>0.60786</td></tr><tr><td>val_brier_loss</td><td>0.06979</td></tr><tr><td>val_mae</td><td>0.14888</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40368</td></tr><tr><td>val_mse</td><td>0.07958</td></tr><tr><td>validation/epoch_loss</td><td>0.26325</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26325</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-11-36</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/2l36l1wo' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/2l36l1wo</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_221138-2l36l1wo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hi16bue3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.5, 0.25, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_222051-hi16bue3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hi16bue3' target=\"_blank\">NN Train - 2023-05-29-22-20-47</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hi16bue3' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hi16bue3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2256 - val_loss: 0.2222\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2228 - val_loss: 0.2247\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2231 - val_loss: 0.2322\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2227 - val_loss: 0.2252\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2228 - val_loss: 0.2218\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2221 - val_loss: 0.2213\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2222 - val_loss: 0.2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "430/431 [============================>.] - ETA: 0s - loss: 0.2363"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 31s 42ms/step - loss: 0.2364 - val_loss: 0.2224\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 17s 38ms/step - loss: 0.2220 - val_loss: 0.2224\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 18s 38ms/step - loss: 0.2220 - val_loss: 0.2225\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2222 - val_loss: 0.2216\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2221 - val_loss: 0.2244\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2221 - val_loss: 0.2253\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2221 - val_loss: 0.2241\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2223 - val_loss: 0.2235\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2219 - val_loss: 0.2228\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2217 - val_loss: 0.2219\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2218 - val_loss: 0.2225\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2217 - val_loss: 0.2227\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2216 - val_loss: 0.2233\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2215 - val_loss: 0.2222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "54/54 [==============================] - ETA: 0s - loss: 0.2199"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r54/54 [==============================] - 8s 120ms/step - loss: 0.2199 - val_loss: 0.2206\n",
            "Epoch 2/7\n",
            "54/54 [==============================] - 8s 120ms/step - loss: 0.2191 - val_loss: 0.2207\n",
            "Epoch 3/7\n",
            "54/54 [==============================] - 7s 115ms/step - loss: 0.2192 - val_loss: 0.2208\n",
            "Epoch 4/7\n",
            "54/54 [==============================] - 7s 115ms/step - loss: 0.2191 - val_loss: 0.2208\n",
            "Epoch 5/7\n",
            "54/54 [==============================] - 8s 120ms/step - loss: 0.2191 - val_loss: 0.2205\n",
            "Epoch 6/7\n",
            "54/54 [==============================] - 7s 114ms/step - loss: 0.2190 - val_loss: 0.2208\n",
            "Epoch 7/7\n",
            "54/54 [==============================] - 7s 117ms/step - loss: 0.2191 - val_loss: 0.2212\n",
            "216/216 [==============================] - 6s 20ms/step\n",
            "63/63 [==============================] - 1s 21ms/step\n",
            "31/31 [==============================] - 1s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▃▃▄▅▅▅▆▆▇▇▇█▁▁▂▂▂▃▃▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▄▄▄▃▇█▆▅▄▃▄▄▅▃▁▁▁▁▁▁▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▄▄▄▃▇█▆▅▄▃▄▄▅▃▁▁▁▁▁▁▂</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>6412</td></tr><tr><td>test_auc_score</td><td>0.61304</td></tr><tr><td>test_brier_loss</td><td>0.07101</td></tr><tr><td>test_mae</td><td>0.15456</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40494</td></tr><tr><td>test_mse</td><td>0.07981</td></tr><tr><td>train/epoch_loss</td><td>0.21908</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61762</td></tr><tr><td>train_brier_loss</td><td>0.0702</td></tr><tr><td>train_mae</td><td>0.15396</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40219</td></tr><tr><td>train_mse</td><td>0.07982</td></tr><tr><td>val_auc_score</td><td>0.60762</td></tr><tr><td>val_brier_loss</td><td>0.07003</td></tr><tr><td>val_mae</td><td>0.15369</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40509</td></tr><tr><td>val_mse</td><td>0.08004</td></tr><tr><td>validation/epoch_loss</td><td>0.22116</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.22116</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-20-47</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hi16bue3' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/hi16bue3</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_222051-hi16bue3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4mclpu5v with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 175\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-07\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_222719-4mclpu5v</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/4mclpu5v' target=\"_blank\">NN Train - 2023-05-29-22-27-15</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/4mclpu5v' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/4mclpu5v</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 5s 7ms/step - loss: 0.2835 - val_loss: 0.2849\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2784 - val_loss: 0.2841\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2779 - val_loss: 0.2890\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2776 - val_loss: 0.2825\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2776 - val_loss: 0.2811\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2777 - val_loss: 0.2801\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2771 - val_loss: 0.2825\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2773 - val_loss: 0.2962\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2773 - val_loss: 0.2874\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2773 - val_loss: 0.2804\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2770 - val_loss: 0.2890\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2770 - val_loss: 0.2799\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2772 - val_loss: 0.2847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "431/431 [==============================] - ETA: 0s - loss: 340.3237"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 37s 36ms/step - loss: 340.3237 - val_loss: 0.2912\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2832 - val_loss: 0.2886\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 15s 31ms/step - loss: 0.2797 - val_loss: 0.2939\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 15s 31ms/step - loss: 0.2781 - val_loss: 0.2840\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2776 - val_loss: 0.2856\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2774 - val_loss: 0.2901\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 15s 32ms/step - loss: 0.2772 - val_loss: 0.2895\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2773 - val_loss: 0.2810\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2771 - val_loss: 0.2788\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2771 - val_loss: 0.2863\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2771 - val_loss: 0.2930\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2771 - val_loss: 0.2897\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2767 - val_loss: 0.2817\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2769 - val_loss: 0.2914\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2769 - val_loss: 0.2778\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2769 - val_loss: 0.2891\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2768 - val_loss: 0.2856\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2770 - val_loss: 0.2902\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2768 - val_loss: 0.2832\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2768 - val_loss: 0.2790\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2767 - val_loss: 0.2857\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2768 - val_loss: 0.2833\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2765 - val_loss: 0.2930\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2765 - val_loss: 0.2840\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 14s 30ms/step - loss: 0.2765 - val_loss: 0.2846\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 14s 31ms/step - loss: 0.2765 - val_loss: 0.2879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2760"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 5s 135ms/step - loss: 0.2760 - val_loss: 0.2870\n",
            "Epoch 2/13\n",
            "27/27 [==============================] - 4s 121ms/step - loss: 0.2756 - val_loss: 0.2855\n",
            "Epoch 3/13\n",
            "27/27 [==============================] - 4s 120ms/step - loss: 0.2755 - val_loss: 0.2857\n",
            "Epoch 4/13\n",
            "27/27 [==============================] - 5s 123ms/step - loss: 0.2756 - val_loss: 0.2845\n",
            "Epoch 5/13\n",
            "27/27 [==============================] - 4s 119ms/step - loss: 0.2755 - val_loss: 0.2860\n",
            "Epoch 6/13\n",
            "27/27 [==============================] - 5s 131ms/step - loss: 0.2755 - val_loss: 0.2847\n",
            "Epoch 7/13\n",
            "27/27 [==============================] - 4s 119ms/step - loss: 0.2755 - val_loss: 0.2849\n",
            "Epoch 8/13\n",
            "27/27 [==============================] - 5s 123ms/step - loss: 0.2754 - val_loss: 0.2874\n",
            "Epoch 9/13\n",
            "27/27 [==============================] - 5s 130ms/step - loss: 0.2753 - val_loss: 0.2851\n",
            "Epoch 10/13\n",
            "27/27 [==============================] - 5s 124ms/step - loss: 0.2755 - val_loss: 0.2857\n",
            "Epoch 11/13\n",
            "27/27 [==============================] - 4s 120ms/step - loss: 0.2753 - val_loss: 0.2859\n",
            "Epoch 12/13\n",
            "27/27 [==============================] - 5s 133ms/step - loss: 0.2754 - val_loss: 0.2869\n",
            "Epoch 13/13\n",
            "27/27 [==============================] - 4s 117ms/step - loss: 0.2754 - val_loss: 0.2848\n",
            "216/216 [==============================] - 5s 14ms/step\n",
            "63/63 [==============================] - 1s 18ms/step\n",
            "31/31 [==============================] - 1s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇██▁▁▁▂▂▂▃▃▃▃▃▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▇▆█▄▄▆▆▂▁▅█▆▃▇▁▆▄▆▃▂▄▃█▄▄▅▅▄▄▄▅▄▄▅▄▄▅▅▄</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▇▆█▄▄▆▆▂▁▅█▆▃▇▁▆▄▆▃▂▄▃█▄▄▅▅▄▄▄▅▄▄▅▄▄▅▅▄</td></tr><tr><td>validation/global_step</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▃▄▄▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11557</td></tr><tr><td>test_auc_score</td><td>0.61208</td></tr><tr><td>test_brier_loss</td><td>0.07224</td></tr><tr><td>test_mae</td><td>0.15457</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.41722</td></tr><tr><td>test_mse</td><td>0.08235</td></tr><tr><td>train/epoch_loss</td><td>0.27541</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.61745</td></tr><tr><td>train_brier_loss</td><td>0.07133</td></tr><tr><td>train_mae</td><td>0.15372</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.41296</td></tr><tr><td>train_mse</td><td>0.08208</td></tr><tr><td>val_auc_score</td><td>0.60714</td></tr><tr><td>val_brier_loss</td><td>0.07123</td></tr><tr><td>val_mae</td><td>0.15365</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.41794</td></tr><tr><td>val_mse</td><td>0.08266</td></tr><tr><td>validation/epoch_loss</td><td>0.28481</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.28481</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-27-15</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/4mclpu5v' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/4mclpu5v</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_222719-4mclpu5v/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gjvtfz5j with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [1, 0, 0, 0]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_223649-gjvtfz5j</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/gjvtfz5j' target=\"_blank\">NN Train - 2023-05-29-22-36-46</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/gjvtfz5j' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/gjvtfz5j</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 5s 6ms/step - loss: 0.2831 - val_loss: 0.2825\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2792 - val_loss: 0.2824\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2790 - val_loss: 0.2822\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2788 - val_loss: 0.2811\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2789 - val_loss: 0.2849\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2787 - val_loss: 0.2788\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2786 - val_loss: 0.2858\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.7372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 30s 39ms/step - loss: 0.7372 - val_loss: 0.2861\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2795 - val_loss: 0.2820\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2774 - val_loss: 0.2795\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2773 - val_loss: 0.2805\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2773 - val_loss: 0.2779\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2770 - val_loss: 0.2777\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2772 - val_loss: 0.2784\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2773 - val_loss: 0.2781\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2768 - val_loss: 0.2786\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2768 - val_loss: 0.2813\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2770 - val_loss: 0.2777\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2770 - val_loss: 0.2832\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2767 - val_loss: 0.2790\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2770 - val_loss: 0.2803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - ETA: 0s - loss: 0.2768"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 16s 35ms/step - loss: 0.2768 - val_loss: 0.2826\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2767 - val_loss: 0.2897\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2768 - val_loss: 0.2807\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2769 - val_loss: 0.2788\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2768 - val_loss: 0.2833\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2767 - val_loss: 0.2782\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 16s 34ms/step - loss: 0.2766 - val_loss: 0.2795\n",
            "216/216 [==============================] - 5s 17ms/step\n",
            "63/63 [==============================] - 1s 21ms/step\n",
            "31/31 [==============================] - 1s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▃▄▄▅▅▆▆▇▇▇█▁▁▂▂▂▂▃▃▃▄▄</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▆▄▂▃▁▁▁▁▂▃▁▄▂▃▄█▃▂▄▁▂</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▆▄▂▃▁▁▁▁▂▃▁▄▂▃▄█▃▂▄▁▂</td></tr><tr><td>validation/global_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█▁▂▂▃▃▄▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>9051</td></tr><tr><td>test_auc_score</td><td>0.60966</td></tr><tr><td>test_brier_loss</td><td>0.07078</td></tr><tr><td>test_mae</td><td>0.14283</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.4065</td></tr><tr><td>test_mse</td><td>0.07929</td></tr><tr><td>train/epoch_loss</td><td>0.27659</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.61437</td></tr><tr><td>train_brier_loss</td><td>0.06998</td></tr><tr><td>train_mae</td><td>0.14215</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.40306</td></tr><tr><td>train_mse</td><td>0.07936</td></tr><tr><td>val_auc_score</td><td>0.60478</td></tr><tr><td>val_brier_loss</td><td>0.06978</td></tr><tr><td>val_mae</td><td>0.14195</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40617</td></tr><tr><td>val_mse</td><td>0.0795</td></tr><tr><td>validation/epoch_loss</td><td>0.27945</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.27945</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-36-46</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/gjvtfz5j' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/gjvtfz5j</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_223649-gjvtfz5j/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pur0uyay with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.075\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.75, 0.15, 0.05, 0.05]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 100\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_224411-pur0uyay</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/pur0uyay' target=\"_blank\">NN Train - 2023-05-29-22-44-08</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/pur0uyay' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/pur0uyay</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "431/431 [==============================] - 4s 6ms/step - loss: 0.2692 - val_loss: 0.2647\n",
            "Epoch 2/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2638 - val_loss: 0.2656\n",
            "Epoch 3/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2626 - val_loss: 0.2634\n",
            "Epoch 4/13\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2622 - val_loss: 0.2632\n",
            "Epoch 5/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2620 - val_loss: 0.2633\n",
            "Epoch 6/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2618 - val_loss: 0.2633\n",
            "Epoch 7/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2618 - val_loss: 0.2628\n",
            "Epoch 8/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2617 - val_loss: 0.2638\n",
            "Epoch 9/13\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2617 - val_loss: 0.2640\n",
            "Epoch 10/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2616 - val_loss: 0.2629\n",
            "Epoch 11/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2616 - val_loss: 0.2626\n",
            "Epoch 12/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2616 - val_loss: 0.2629\n",
            "Epoch 13/13\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2616 - val_loss: 0.2630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/26\n",
            "430/431 [============================>.] - ETA: 0s - loss: 0.2876"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 31s 40ms/step - loss: 0.2876 - val_loss: 0.2674\n",
            "Epoch 2/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2661 - val_loss: 0.2680\n",
            "Epoch 3/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2651 - val_loss: 0.2654\n",
            "Epoch 4/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2642 - val_loss: 0.2667\n",
            "Epoch 5/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2635 - val_loss: 0.2661\n",
            "Epoch 6/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2630 - val_loss: 0.2655\n",
            "Epoch 7/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2626 - val_loss: 0.2645\n",
            "Epoch 8/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2624 - val_loss: 0.2646\n",
            "Epoch 9/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2622 - val_loss: 0.2631\n",
            "Epoch 10/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2618 - val_loss: 0.2635\n",
            "Epoch 11/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2617 - val_loss: 0.2649\n",
            "Epoch 12/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2617 - val_loss: 0.2637\n",
            "Epoch 13/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2615 - val_loss: 0.2652\n",
            "Epoch 14/26\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2614 - val_loss: 0.2633\n",
            "Epoch 15/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2614 - val_loss: 0.2633\n",
            "Epoch 16/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2613 - val_loss: 0.2628\n",
            "Epoch 17/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2612 - val_loss: 0.2635\n",
            "Epoch 18/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2613 - val_loss: 0.2630\n",
            "Epoch 19/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2612 - val_loss: 0.2630\n",
            "Epoch 20/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2612 - val_loss: 0.2634\n",
            "Epoch 21/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2612 - val_loss: 0.2628\n",
            "Epoch 22/26\n",
            "431/431 [==============================] - 16s 35ms/step - loss: 0.2612 - val_loss: 0.2630\n",
            "Epoch 23/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2611 - val_loss: 0.2642\n",
            "Epoch 24/26\n",
            "431/431 [==============================] - 17s 38ms/step - loss: 0.2611 - val_loss: 0.2628\n",
            "Epoch 25/26\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2611 - val_loss: 0.2639\n",
            "Epoch 26/26\n",
            "431/431 [==============================] - 16s 36ms/step - loss: 0.2611 - val_loss: 0.2654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/13\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2609"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 8s 229ms/step - loss: 0.2609 - val_loss: 0.2629\n",
            "Epoch 2/13\n",
            "27/27 [==============================] - 7s 217ms/step - loss: 0.2604 - val_loss: 0.2625\n",
            "Epoch 3/13\n",
            "27/27 [==============================] - 7s 220ms/step - loss: 0.2602 - val_loss: 0.2626\n",
            "Epoch 4/13\n",
            "27/27 [==============================] - 7s 221ms/step - loss: 0.2602 - val_loss: 0.2625\n",
            "Epoch 5/13\n",
            "27/27 [==============================] - 7s 221ms/step - loss: 0.2602 - val_loss: 0.2625\n",
            "Epoch 6/13\n",
            "27/27 [==============================] - 7s 218ms/step - loss: 0.2601 - val_loss: 0.2626\n",
            "Epoch 7/13\n",
            "27/27 [==============================] - 7s 216ms/step - loss: 0.2601 - val_loss: 0.2626\n",
            "Epoch 8/13\n",
            "27/27 [==============================] - 7s 214ms/step - loss: 0.2601 - val_loss: 0.2625\n",
            "Epoch 9/13\n",
            "27/27 [==============================] - 7s 222ms/step - loss: 0.2601 - val_loss: 0.2627\n",
            "Epoch 10/13\n",
            "27/27 [==============================] - 7s 213ms/step - loss: 0.2601 - val_loss: 0.2626\n",
            "Epoch 11/13\n",
            "27/27 [==============================] - 7s 218ms/step - loss: 0.2600 - val_loss: 0.2626\n",
            "Epoch 12/13\n",
            "27/27 [==============================] - 7s 217ms/step - loss: 0.2601 - val_loss: 0.2626\n",
            "Epoch 13/13\n",
            "27/27 [==============================] - 7s 217ms/step - loss: 0.2601 - val_loss: 0.2626\n",
            "216/216 [==============================] - 6s 20ms/step\n",
            "63/63 [==============================] - 1s 19ms/step\n",
            "31/31 [==============================] - 1s 18ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇███████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇██▁▁▂▂▂▂▃▃▄▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>▇█▅▆▅▅▃▄▂▂▄▂▄▂▂▁▂▂▂▂▁▂▃▁▃▅▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>▇█▅▆▅▅▃▄▂▂▄▂▄▂▂▁▂▂▂▂▁▂▃▁▃▅▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>11557</td></tr><tr><td>test_auc_score</td><td>0.61298</td></tr><tr><td>test_brier_loss</td><td>0.07062</td></tr><tr><td>test_mae</td><td>0.14794</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40208</td></tr><tr><td>test_mse</td><td>0.07909</td></tr><tr><td>train/epoch_loss</td><td>0.2601</td></tr><tr><td>train/global_step</td><td>12</td></tr><tr><td>train_auc_score</td><td>0.62538</td></tr><tr><td>train_brier_loss</td><td>0.06968</td></tr><tr><td>train_mae</td><td>0.14715</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39759</td></tr><tr><td>train_mse</td><td>0.079</td></tr><tr><td>val_auc_score</td><td>0.60847</td></tr><tr><td>val_brier_loss</td><td>0.06965</td></tr><tr><td>val_mae</td><td>0.1472</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40194</td></tr><tr><td>val_mse</td><td>0.07933</td></tr><tr><td>validation/epoch_loss</td><td>0.26263</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26263</td></tr><tr><td>validation/global_step</td><td>12</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">NN Train - 2023-05-29-22-44-08</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/pur0uyay' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/pur0uyay</a><br/>Synced 5 W&B file(s), 3 media file(s), 3 artifact file(s) and 5 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230529_224411-pur0uyay/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7oeq0maf with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_dims: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_heads: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention_output_dims: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tburnin_multiplier: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tclaim_dense: 250\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_other_block_width: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdense_res_block_width: 150\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdriver_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.05\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinitial_bias: -2.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tkeep_trainable: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.025\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tloss_weight: [0.9, 0.04, 0.03, 0.03]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trelu_leakiness: 0.015\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tveh_dense: 200\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 1e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230529_225444-7oeq0maf</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/7oeq0maf' target=\"_blank\">NN Train - 2023-05-29-22-54-41</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/sweeps/xw6922l1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/7oeq0maf' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/7oeq0maf</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "431/431 [==============================] - 5s 7ms/step - loss: 0.2730 - val_loss: 0.2700\n",
            "Epoch 2/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2689 - val_loss: 0.2723\n",
            "Epoch 3/7\n",
            "431/431 [==============================] - 2s 5ms/step - loss: 0.2688 - val_loss: 0.2697\n",
            "Epoch 4/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2685 - val_loss: 0.2699\n",
            "Epoch 5/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2683 - val_loss: 0.2693\n",
            "Epoch 6/7\n",
            "431/431 [==============================] - 2s 6ms/step - loss: 0.2683 - val_loss: 0.2697\n",
            "Epoch 7/7\n",
            "431/431 [==============================] - 3s 6ms/step - loss: 0.2682 - val_loss: 0.2691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/14\n",
            "431/431 [==============================] - ETA: 0s - loss: 52902.3320"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r431/431 [==============================] - 32s 42ms/step - loss: 52902.3320 - val_loss: 0.3070\n",
            "Epoch 2/14\n",
            "431/431 [==============================] - 18s 38ms/step - loss: 0.2771 - val_loss: 0.2726\n",
            "Epoch 3/14\n",
            "431/431 [==============================] - 17s 36ms/step - loss: 0.2702 - val_loss: 0.2723\n",
            "Epoch 4/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2687 - val_loss: 0.2696\n",
            "Epoch 5/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2682 - val_loss: 0.2695\n",
            "Epoch 6/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2679 - val_loss: 0.2688\n",
            "Epoch 7/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2679 - val_loss: 0.2692\n",
            "Epoch 8/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2677 - val_loss: 0.2686\n",
            "Epoch 9/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2675 - val_loss: 0.2698\n",
            "Epoch 10/14\n",
            "431/431 [==============================] - 17s 38ms/step - loss: 0.2677 - val_loss: 0.2689\n",
            "Epoch 11/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2676 - val_loss: 0.2710\n",
            "Epoch 12/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2676 - val_loss: 0.2694\n",
            "Epoch 13/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2676 - val_loss: 0.2689\n",
            "Epoch 14/14\n",
            "431/431 [==============================] - 17s 37ms/step - loss: 0.2674 - val_loss: 0.2692\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "27/27 [==============================] - ETA: 0s - loss: 0.2671"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r27/27 [==============================] - 9s 272ms/step - loss: 0.2671 - val_loss: 0.2685\n",
            "Epoch 2/7\n",
            "27/27 [==============================] - 8s 268ms/step - loss: 0.2667 - val_loss: 0.2687\n",
            "Epoch 3/7\n",
            "27/27 [==============================] - 8s 267ms/step - loss: 0.2667 - val_loss: 0.2686\n",
            "Epoch 4/7\n",
            "27/27 [==============================] - 8s 266ms/step - loss: 0.2666 - val_loss: 0.2686\n",
            "Epoch 5/7\n",
            "27/27 [==============================] - 8s 270ms/step - loss: 0.2666 - val_loss: 0.2686\n",
            "Epoch 6/7\n",
            "27/27 [==============================] - 8s 265ms/step - loss: 0.2666 - val_loss: 0.2686\n",
            "Epoch 7/7\n",
            "27/27 [==============================] - 8s 263ms/step - loss: 0.2665 - val_loss: 0.2686\n",
            "216/216 [==============================] - 6s 23ms/step\n",
            "63/63 [==============================] - 1s 19ms/step\n",
            "31/31 [==============================] - 1s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇██████████████</td></tr><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train/epoch_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▃▄▅▅▅▅▆▆▇▇█▁▁▂▂▃▃▄▅</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr><tr><td>validation/epoch_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>validation/global_step</td><td>▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>6223</td></tr><tr><td>test_auc_score</td><td>0.61299</td></tr><tr><td>test_brier_loss</td><td>0.07057</td></tr><tr><td>test_mae</td><td>0.14779</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40152</td></tr><tr><td>test_mse</td><td>0.07902</td></tr><tr><td>train/epoch_loss</td><td>0.26652</td></tr><tr><td>train/global_step</td><td>6</td></tr><tr><td>train_auc_score</td><td>0.62105</td></tr><tr><td>train_brier_loss</td><td>0.06974</td></tr><tr><td>train_mae</td><td>0.14713</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.39833</td></tr><tr><td>train_mse</td><td>0.07907</td></tr><tr><td>val_auc_score</td><td>0.60799</td></tr><tr><td>val_brier_loss</td><td>0.06958</td></tr><tr><td>val_mae</td><td>0.14705</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40125</td></tr><tr><td>val_mse</td><td>0.07925</td></tr><tr><td>validation/epoch_loss</td><td>0.26863</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>0.26863</td></tr><tr><td>validation/global_step</td><td>6</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# main(config = {\n",
        "#         \"epochs\": 50,\n",
        "#         \"learning_rate\": 0.01,\n",
        "#         \"weight_decay\": 0.00001,\n",
        "#         \"relu_leakiness\": 0.015,\n",
        "#         \"driver_dense\": 15,\n",
        "#         \"veh_dense\": 20,\n",
        "#         \"claim_dense\": 25,\n",
        "#         \"attention_heads\": 1,\n",
        "#         \"attention_dims\": 10,\n",
        "#         \"attention_output_dims\": 10,\n",
        "#         \"dense_res_block_width\": 25,\n",
        "#         \"dense_other_block_width\": 100,\n",
        "#         \"dropout\": 0.05,\n",
        "#         \"batch_size\": 1024,\n",
        "#         \"initial_bias\": -2.5,\n",
        "#         \"loss_weight\": [0.7, 0.1, 0.1, 0.1], # [1, 0, 0, 0] [0.4, 0.2, 0.2, 0.2] [0.55, 0.15, 0.15, 0.15] [0.7, 0.1, 0.1, 0.1] [0.85, 0.05, 0.05, 0.05] [0.75, 0.15, 0.05, 0.05] [0.4, 0.3, 0.1, 0.1] [0.25, 0.25, 0.25, 0.25],\n",
        "#         \"keep_trainable\": False,\n",
        "#         \"burnin_multiplier\": 16\n",
        "#   })\n",
        "\n",
        "wandb.agent(entity = \"msds_498_claims_modeling\", project = \"claims_modeling\", sweep_id=\"xw6922l1\", function=main, count = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXejY4QRrLph"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}