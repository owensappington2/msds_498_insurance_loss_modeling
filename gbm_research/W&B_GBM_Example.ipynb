{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j42lIAAKx24d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39f0e31-6a0b-46ec-c17a-7946a1159041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.22.2)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn.metrics import (\n",
        "    mean_squared_error, mean_absolute_error, mean_poisson_deviance, \n",
        "    brier_score_loss, roc_auc_score, roc_curve, RocCurveDisplay\n",
        ")\n",
        "\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "import wandb\n",
        "wandb.login(relogin = True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "cHjGvQZ5yJL7",
        "outputId": "80d26c75-d0f5-450a-f89a-f2b1ddd5bbb9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "  project=\"claims_modeling\",\n",
        "  group = 'demo',\n",
        "  name = f'W&B Tutorial - {datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}',\n",
        "  notes=\"Just Playing Around!\",\n",
        "  tags=[\"gbm\"],\n",
        "  save_code = True,\n",
        "  config = {\n",
        "        \"n_estimators\": 500,\n",
        "        \"learning_rate\": 0.05,\n",
        "        \"max_depth\": 3,\n",
        "        \"subsample\": 0.5,\n",
        "        \"n_iter_no_change\": 20,\n",
        "        \"max_features\": 'log2',\n",
        "        'x': ['vehicle_age', 'annual_mileage', 'max_driver_age', 'min_driver_age',\\\n",
        "        'mean_driver_age', 'min_driver_tenure', 'youthful_driver_count', 'credit_score',\\\n",
        "        'household_tenure','multiline_houses', 'multiline_personal_article_policy', \\\n",
        "        'multiline_personal_liability_umbrella', 'multiline_rental', 'vehicle_count', 'vehicle_claim_time_since_all', \\\n",
        "        'driver_count','coverage_bi','coverage_coll','coverage_comp','coverage_ers','coverage_mpc','coverage_pd','coverage_ubi', \\\n",
        "        'vehicle_type',  'garaging_location'\n",
        "      ],\n",
        "        'y': 'vehicle_claim_cnt_pd_0'\n",
        "  }\n",
        ")\n",
        "\n",
        "#"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "ZgWaRkfmx3zQ",
        "outputId": "b7ba8ee9-3702-44ba-c2c1-132a82dca417"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtylerrosacker2022\u001b[0m (\u001b[33mmsds_498_claims_modeling\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230514_001119-g3bcfy74</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g3bcfy74' target=\"_blank\">W&B Tutorial - 2023-05-14-00-11-19</a></strong> to <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g3bcfy74' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g3bcfy74</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Datasets and Feature Prep"
      ],
      "metadata": {
        "id": "yON7s0olFOWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datas = run.use_artifact('msds_498_claims_modeling/claims_modeling/sythetic_data:v5')\n",
        "directory = datas.download(root = 'datasets')\n",
        "\n",
        "train_df = pd.read_parquet('datasets/split=train')\n",
        "test_df = pd.read_parquet('datasets/split=test')\n",
        "val_df = pd.read_parquet('datasets/split=validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8O7hWpomSzZ",
        "outputId": "89bfc561-f630-4924-9625-d4ecb2bcc38d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact sythetic_data:v5, 153.76MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = run.use_artifact('msds_498_claims_modeling/claims_modeling/sythetic_data:v5')\n",
        "directory = datas.download(root = 'datasets')\n",
        "\n",
        "replace_vals = {\n",
        "    'vehicle_type': {'van': 1, 'sports car': 2, 'pickup': 3, 'sedan': 4, 'suv': 5},\n",
        "    'garaging_location': {'country': 1, 'downtown': 2, 'suburb': 3}\n",
        "    }\n",
        "\n",
        "train_df = pd.read_parquet('datasets/split=train').replace(replace_vals)\n",
        "test_df = pd.read_parquet('datasets/split=test').replace(replace_vals)\n",
        "val_df = pd.read_parquet('datasets/split=validation').replace(replace_vals)\n",
        "\n",
        "train_x = train_df[run.config['x']]\n",
        "test_x = test_df[run.config['x']]\n",
        "val_x = val_df[run.config['x']]\n",
        "\n",
        "train_y = train_df[run.config['y']]\n",
        "test_y = test_df[run.config['y']]\n",
        "val_y = val_df[run.config['y']]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcJng7o1yPwb",
        "outputId": "ba5bbc42-a794-4f6b-d047-4f843d69c651"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact sythetic_data:v5, 153.76MB. 3 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   3 of 3 files downloaded.  \n",
            "Done. 0:0:0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model Object"
      ],
      "metadata": {
        "id": "5BEU3NiIFRjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = HistGradientBoostingRegressor(\n",
        "    max_iter=run.config['n_estimators'],\n",
        "    learning_rate=run.config['learning_rate'],\n",
        "    max_depth=run.config['max_depth'],\n",
        "    #min_samples_leafint=run.config['subsample'],\n",
        "    validation_fraction=0.1,\n",
        "    n_iter_no_change=run.config['n_iter_no_change'],\n",
        "    #max_features=run.config['max_features'],\n",
        "    loss=\"poisson\",\n",
        "    categorical_features = [x for x in run.config['x'] if x in ['vehicle_type', 'garaging_location']],\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "DkOWfZiU081u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "NSMk9TioFTi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X = train_x, \n",
        "          y = train_y\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o1VtWmBU0gE6",
        "outputId": "b5aa7376-6be9-49e3-bb62-0fb755f14cac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binning 0.040 GB of training data: 0.486 s\n",
            "Binning 0.004 GB of validation data: 0.015 s\n",
            "Fitting gradient boosted rounds:\n",
            "[1/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.28133, val loss: 0.28013, in 0.036s\n",
            "[2/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.28089, val loss: 0.27974, in 0.033s\n",
            "[3/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.28048, val loss: 0.27940, in 0.035s\n",
            "[4/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.28012, val loss: 0.27908, in 0.044s\n",
            "[5/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27979, val loss: 0.27882, in 0.031s\n",
            "[6/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27946, val loss: 0.27855, in 0.036s\n",
            "[7/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27918, val loss: 0.27829, in 0.042s\n",
            "[8/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27890, val loss: 0.27806, in 0.045s\n",
            "[9/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27866, val loss: 0.27788, in 0.033s\n",
            "[10/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27842, val loss: 0.27769, in 0.036s\n",
            "[11/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27822, val loss: 0.27752, in 0.036s\n",
            "[12/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27802, val loss: 0.27735, in 0.035s\n",
            "[13/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27783, val loss: 0.27719, in 0.043s\n",
            "[14/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27766, val loss: 0.27706, in 0.035s\n",
            "[15/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27749, val loss: 0.27693, in 0.036s\n",
            "[16/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27733, val loss: 0.27680, in 0.038s\n",
            "[17/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27719, val loss: 0.27670, in 0.032s\n",
            "[18/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27706, val loss: 0.27658, in 0.044s\n",
            "[19/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27693, val loss: 0.27648, in 0.043s\n",
            "[20/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27681, val loss: 0.27637, in 0.033s\n",
            "[21/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27670, val loss: 0.27629, in 0.034s\n",
            "[22/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27659, val loss: 0.27620, in 0.037s\n",
            "[23/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27650, val loss: 0.27611, in 0.032s\n",
            "[24/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27640, val loss: 0.27603, in 0.036s\n",
            "[25/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27632, val loss: 0.27597, in 0.065s\n",
            "[26/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27623, val loss: 0.27588, in 0.035s\n",
            "[27/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27615, val loss: 0.27581, in 0.034s\n",
            "[28/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27607, val loss: 0.27576, in 0.035s\n",
            "[29/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27600, val loss: 0.27570, in 0.036s\n",
            "[30/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27593, val loss: 0.27565, in 0.040s\n",
            "[31/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27587, val loss: 0.27559, in 0.032s\n",
            "[32/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27581, val loss: 0.27555, in 0.033s\n",
            "[33/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27575, val loss: 0.27552, in 0.054s\n",
            "[34/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27569, val loss: 0.27547, in 0.033s\n",
            "[35/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27563, val loss: 0.27543, in 0.035s\n",
            "[36/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27557, val loss: 0.27538, in 0.035s\n",
            "[37/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27553, val loss: 0.27535, in 0.044s\n",
            "[38/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27548, val loss: 0.27531, in 0.044s\n",
            "[39/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27543, val loss: 0.27528, in 0.032s\n",
            "[40/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27538, val loss: 0.27524, in 0.032s\n",
            "[41/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27534, val loss: 0.27523, in 0.031s\n",
            "[42/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27530, val loss: 0.27519, in 0.038s\n",
            "[43/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27526, val loss: 0.27517, in 0.032s\n",
            "[44/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27522, val loss: 0.27514, in 0.037s\n",
            "[45/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27518, val loss: 0.27512, in 0.034s\n",
            "[46/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27515, val loss: 0.27510, in 0.036s\n",
            "[47/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27511, val loss: 0.27508, in 0.029s\n",
            "[48/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27508, val loss: 0.27506, in 0.032s\n",
            "[49/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27505, val loss: 0.27505, in 0.032s\n",
            "[50/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27502, val loss: 0.27502, in 0.037s\n",
            "[51/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27499, val loss: 0.27501, in 0.033s\n",
            "[52/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27496, val loss: 0.27499, in 0.049s\n",
            "[53/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27492, val loss: 0.27496, in 0.031s\n",
            "[54/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27490, val loss: 0.27494, in 0.037s\n",
            "[55/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27487, val loss: 0.27493, in 0.029s\n",
            "[56/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27484, val loss: 0.27491, in 0.033s\n",
            "[57/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27482, val loss: 0.27489, in 0.032s\n",
            "[58/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27480, val loss: 0.27488, in 0.036s\n",
            "[59/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27477, val loss: 0.27488, in 0.044s\n",
            "[60/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27475, val loss: 0.27486, in 0.041s\n",
            "[61/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27473, val loss: 0.27484, in 0.037s\n",
            "[62/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27471, val loss: 0.27483, in 0.032s\n",
            "[63/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27469, val loss: 0.27483, in 0.032s\n",
            "[64/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27466, val loss: 0.27480, in 0.037s\n",
            "[65/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27465, val loss: 0.27479, in 0.035s\n",
            "[66/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27463, val loss: 0.27478, in 0.052s\n",
            "[67/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27461, val loss: 0.27478, in 0.034s\n",
            "[68/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27459, val loss: 0.27477, in 0.031s\n",
            "[69/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27457, val loss: 0.27478, in 0.029s\n",
            "[70/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27455, val loss: 0.27476, in 0.033s\n",
            "[71/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27454, val loss: 0.27475, in 0.033s\n",
            "[72/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27452, val loss: 0.27475, in 0.030s\n",
            "[73/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27450, val loss: 0.27475, in 0.033s\n",
            "[74/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27449, val loss: 0.27474, in 0.041s\n",
            "[75/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27448, val loss: 0.27474, in 0.045s\n",
            "[76/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27446, val loss: 0.27474, in 0.065s\n",
            "[77/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27444, val loss: 0.27474, in 0.062s\n",
            "[78/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27443, val loss: 0.27473, in 0.070s\n",
            "[79/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27442, val loss: 0.27473, in 0.057s\n",
            "[80/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27440, val loss: 0.27472, in 0.081s\n",
            "[81/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27439, val loss: 0.27472, in 0.068s\n",
            "[82/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27437, val loss: 0.27470, in 0.079s\n",
            "[83/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27436, val loss: 0.27469, in 0.064s\n",
            "[84/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27435, val loss: 0.27469, in 0.685s\n",
            "[85/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27433, val loss: 0.27469, in 1.010s\n",
            "[86/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27432, val loss: 0.27469, in 0.689s\n",
            "[87/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27430, val loss: 0.27469, in 0.061s\n",
            "[88/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27429, val loss: 0.27468, in 0.030s\n",
            "[89/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27428, val loss: 0.27467, in 0.034s\n",
            "[90/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27427, val loss: 0.27465, in 0.033s\n",
            "[91/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27426, val loss: 0.27465, in 0.033s\n",
            "[92/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27425, val loss: 0.27464, in 0.038s\n",
            "[93/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27424, val loss: 0.27464, in 0.039s\n",
            "[94/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27422, val loss: 0.27464, in 0.032s\n",
            "[95/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27421, val loss: 0.27465, in 0.033s\n",
            "[96/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27420, val loss: 0.27465, in 0.030s\n",
            "[97/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27419, val loss: 0.27464, in 0.030s\n",
            "[98/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27418, val loss: 0.27464, in 0.029s\n",
            "[99/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27417, val loss: 0.27464, in 0.033s\n",
            "[100/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27416, val loss: 0.27464, in 0.031s\n",
            "[101/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27415, val loss: 0.27464, in 0.031s\n",
            "[102/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27414, val loss: 0.27463, in 0.034s\n",
            "[103/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27413, val loss: 0.27463, in 0.043s\n",
            "[104/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27412, val loss: 0.27462, in 0.045s\n",
            "[105/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27411, val loss: 0.27462, in 0.031s\n",
            "[106/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27410, val loss: 0.27463, in 0.039s\n",
            "[107/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27409, val loss: 0.27463, in 0.031s\n",
            "[108/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27408, val loss: 0.27463, in 0.033s\n",
            "[109/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27407, val loss: 0.27462, in 0.032s\n",
            "[110/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27406, val loss: 0.27462, in 0.046s\n",
            "[111/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27405, val loss: 0.27462, in 0.047s\n",
            "[112/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27404, val loss: 0.27461, in 0.035s\n",
            "[113/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27403, val loss: 0.27461, in 0.036s\n",
            "[114/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27402, val loss: 0.27460, in 0.032s\n",
            "[115/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27401, val loss: 0.27461, in 0.029s\n",
            "[116/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27400, val loss: 0.27461, in 0.036s\n",
            "[117/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27460, in 0.035s\n",
            "[118/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27398, val loss: 0.27461, in 0.036s\n",
            "[119/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27397, val loss: 0.27461, in 0.044s\n",
            "[120/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27396, val loss: 0.27461, in 0.029s\n",
            "[121/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27395, val loss: 0.27461, in 0.035s\n",
            "[122/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27394, val loss: 0.27461, in 0.033s\n",
            "[123/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27393, val loss: 0.27460, in 0.034s\n",
            "[124/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27392, val loss: 0.27460, in 0.030s\n",
            "[125/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27391, val loss: 0.27460, in 0.034s\n",
            "[126/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27390, val loss: 0.27460, in 0.034s\n",
            "[127/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27389, val loss: 0.27460, in 0.046s\n",
            "[128/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27388, val loss: 0.27460, in 0.037s\n",
            "[129/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27387, val loss: 0.27460, in 0.028s\n",
            "[130/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27386, val loss: 0.27460, in 0.050s\n",
            "[131/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27386, val loss: 0.27459, in 0.027s\n",
            "[132/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27385, val loss: 0.27459, in 0.041s\n",
            "[133/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27384, val loss: 0.27459, in 0.036s\n",
            "[134/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27383, val loss: 0.27458, in 0.028s\n",
            "[135/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27382, val loss: 0.27458, in 0.044s\n",
            "[136/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27382, val loss: 0.27459, in 0.032s\n",
            "[137/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27381, val loss: 0.27459, in 0.027s\n",
            "[138/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27380, val loss: 0.27459, in 0.033s\n",
            "[139/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27379, val loss: 0.27459, in 0.036s\n",
            "[140/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27378, val loss: 0.27459, in 0.028s\n",
            "[141/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27377, val loss: 0.27459, in 0.031s\n",
            "[142/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27376, val loss: 0.27460, in 0.028s\n",
            "[143/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27376, val loss: 0.27459, in 0.034s\n",
            "[144/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27375, val loss: 0.27459, in 0.033s\n",
            "[145/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27374, val loss: 0.27459, in 0.029s\n",
            "[146/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27373, val loss: 0.27459, in 0.030s\n",
            "[147/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27372, val loss: 0.27459, in 0.039s\n",
            "[148/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27372, val loss: 0.27459, in 0.032s\n",
            "[149/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27371, val loss: 0.27458, in 0.030s\n",
            "[150/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27370, val loss: 0.27459, in 0.028s\n",
            "[151/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27369, val loss: 0.27459, in 0.041s\n",
            "[152/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27369, val loss: 0.27459, in 0.033s\n",
            "[153/500] 1 tree, 6 leaves, max depth = 3, train loss: 0.27368, val loss: 0.27459, in 0.025s\n",
            "[154/500] 1 tree, 8 leaves, max depth = 3, train loss: 0.27367, val loss: 0.27458, in 0.035s\n",
            "Fit 154 trees in 9.006 s, (1230 total leaves)\n",
            "Time spent computing histograms: 3.457s\n",
            "Time spent finding best splits:  0.515s\n",
            "Time spent applying splits:      1.486s\n",
            "Time spent predicting:           0.106s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HistGradientBoostingRegressor(categorical_features=['vehicle_type',\n",
              "                                                    'garaging_location'],\n",
              "                              learning_rate=0.05, loss='poisson', max_depth=3,\n",
              "                              max_iter=500, n_iter_no_change=20, verbose=1)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>HistGradientBoostingRegressor(categorical_features=[&#x27;vehicle_type&#x27;,\n",
              "                                                    &#x27;garaging_location&#x27;],\n",
              "                              learning_rate=0.05, loss=&#x27;poisson&#x27;, max_depth=3,\n",
              "                              max_iter=500, n_iter_no_change=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">HistGradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>HistGradientBoostingRegressor(categorical_features=[&#x27;vehicle_type&#x27;,\n",
              "                                                    &#x27;garaging_location&#x27;],\n",
              "                              learning_rate=0.05, loss=&#x27;poisson&#x27;, max_depth=3,\n",
              "                              max_iter=500, n_iter_no_change=20, verbose=1)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validation"
      ],
      "metadata": {
        "id": "NdPTWv7-FVo3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = model.predict(train_x)\n",
        "test_pred = model.predict(test_x)\n",
        "val_pred = model.predict(val_x)"
      ],
      "metadata": {
        "id": "RK5lkEfl1moI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_stats(dataset_name, prediction, truth):\n",
        "  prediction = np.clip(prediction, a_min = 0.001, a_max = np.inf)\n",
        "  predicted_p_gt_0 = np.clip(1 - np.exp(-prediction), a_min = 0, a_max = 1)\n",
        "  truth_capped = np.clip(truth, a_min = 0, a_max = 1)\n",
        "\n",
        "  fpr, tpr, _ = roc_curve(truth_capped, predicted_p_gt_0)\n",
        "  roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
        "  \n",
        "  metrics = {\n",
        "      f\"{dataset_name}_prediction_dist\": wandb.Histogram(prediction),\n",
        "      f\"{dataset_name}_mse\": mean_squared_error(truth, prediction), \n",
        "      f\"{dataset_name}_mae\": mean_absolute_error(truth, prediction),\n",
        "      f\"{dataset_name}_mean_poisson_deviance\": mean_poisson_deviance(truth, prediction),\n",
        "      f\"{dataset_name}_brier_loss\": brier_score_loss(truth_capped, predicted_p_gt_0),\n",
        "      f\"{dataset_name}_auc_score\": roc_auc_score(truth_capped, predicted_p_gt_0),\n",
        "      f\"{dataset_name}_roc\": roc_display.figure_\n",
        "    }\n",
        "  wandb.log(metrics)\n",
        "  \n",
        "\n",
        "log_stats('train', train_pred, train_y)\n",
        "log_stats('test', test_pred, test_y)\n",
        "log_stats('val', val_pred, val_y)"
      ],
      "metadata": {
        "id": "x5jp8iX24cHN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model and Close Out"
      ],
      "metadata": {
        "id": "2xjwORECPsNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model, open('model.plk', 'wb'))\n",
        "wandb.save('model.plk')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3OcOblckPmmL",
        "outputId": "c0981a6c-c8c8-46f3-c347-efa3d214bffd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/wandb/run-20230514_001119-g3bcfy74/files/model.plk']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "chFjNe5F503k",
        "outputId": "1455ba2a-4a27-4d31-fb7a-649f787c8c77"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_auc_score</td><td>▁</td></tr><tr><td>test_brier_loss</td><td>▁</td></tr><tr><td>test_mae</td><td>▁</td></tr><tr><td>test_mean_poisson_deviance</td><td>▁</td></tr><tr><td>test_mse</td><td>▁</td></tr><tr><td>train_auc_score</td><td>▁</td></tr><tr><td>train_brier_loss</td><td>▁</td></tr><tr><td>train_mae</td><td>▁</td></tr><tr><td>train_mean_poisson_deviance</td><td>▁</td></tr><tr><td>train_mse</td><td>▁</td></tr><tr><td>val_auc_score</td><td>▁</td></tr><tr><td>val_brier_loss</td><td>▁</td></tr><tr><td>val_mae</td><td>▁</td></tr><tr><td>val_mean_poisson_deviance</td><td>▁</td></tr><tr><td>val_mse</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_auc_score</td><td>0.61301</td></tr><tr><td>test_brier_loss</td><td>0.07055</td></tr><tr><td>test_mae</td><td>0.14606</td></tr><tr><td>test_mean_poisson_deviance</td><td>0.40136</td></tr><tr><td>test_mse</td><td>0.07898</td></tr><tr><td>train_auc_score</td><td>0.62635</td></tr><tr><td>train_brier_loss</td><td>0.06963</td></tr><tr><td>train_mae</td><td>0.14534</td></tr><tr><td>train_mean_poisson_deviance</td><td>0.397</td></tr><tr><td>train_mse</td><td>0.07893</td></tr><tr><td>val_auc_score</td><td>0.6085</td></tr><tr><td>val_brier_loss</td><td>0.06954</td></tr><tr><td>val_mae</td><td>0.14532</td></tr><tr><td>val_mean_poisson_deviance</td><td>0.40052</td></tr><tr><td>val_mse</td><td>0.07917</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">W&B Tutorial - 2023-05-14-00-11-19</strong> at: <a href='https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g3bcfy74' target=\"_blank\">https://wandb.ai/msds_498_claims_modeling/claims_modeling/runs/g3bcfy74</a><br/>Synced 5 W&B file(s), 3 media file(s), 17 artifact file(s) and 2 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230514_001119-g3bcfy74/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
